Distribution Mirrors
====================

A distribution mirror must always be associated with a single distribution, so
to create a new mirror you should use the Distribution.newMirror method.

    >>> from datetime import datetime, timedelta
    >>> from zope.component import getUtility
    >>> from canonical.launchpad.interfaces import (
    ...     IDistributionSet, IPersonSet, ICountrySet, IDistroReleaseSet,
    ...     IDistroArchReleaseSet, IDistributionMirrorSet,
    ...     ILibraryFileAliasSet)
    >>> from canonical.lp.dbschema import (
    ...     PackagePublishingPocket, MirrorSpeed, MirrorContent,
    ...     PackagePublishingStatus, MirrorStatus)
    >>> mirrorset = getUtility(IDistributionMirrorSet)
    >>> distroset = getUtility(IDistributionSet)
    >>> ubuntu = distroset.get(1)
    >>> owner = getUtility(IPersonSet).getByName('name16')
    >>> speed = MirrorSpeed.S2M
    >>> country = getUtility(ICountrySet)['BR']
    >>> content = MirrorContent.ARCHIVE
    >>> http_base_url = 'http://foo.bar.com/pub'
    >>> new_mirror = ubuntu.newMirror(
    ...     owner, speed, country, content, http_base_url=http_base_url)
    >>> from canonical.librarian.ftests.harness import LibrarianTestSetup
    >>> LibrarianTestSetup().setUp()

When a new mirror is created we'll generate a unique name for it, based on its
host name and content.

    >>> new_mirror.name
    u'foo.bar.com-archive'

And all mirrors aren't considered one of the official ones until the
distribution's mirror admin has reviewed (and approved) it.

    >>> new_mirror.isOfficial()
    False

You cannot create a new mirror on a distribution that does not have the full
functionality of Launchpad enabled:

    >>> kubuntu = distroset.get(5)
    >>> kubuntu.name
    u'kubuntu'
    >>> poor_mirror = kubuntu.newMirror(
    ...     owner, speed, country, content, http_base_url=http_base_url)
    >>> print poor_mirror
    None

The contents of a distribution mirror are represented by its associated
MirrorDistroArchReleases and MirrorDistroReleaseSources. This data is updated
at least once a day by the distributionmirror-prober cronscript, to make sure
the information we have is always up to date.

    >>> new_mirror.source_releases.count()
    0
    >>> new_mirror.arch_releases.count()
    0

To create a new MirrorDistroArchRelease (or MirrorDistroReleaseSource)
associated with a given mirror, we use the ensureMirrorDistroArchRelease
(or ensureMirrorDistroReleaseSource) method.

    >>> warty = getUtility(IDistroReleaseSet).get(1)
    >>> warty_i386 = getUtility(IDistroArchReleaseSet).get(1)
    >>> pocket = PackagePublishingPocket.RELEASE
    >>> warty_component = warty.components[0]
    >>> warty_i386_mirror = new_mirror.ensureMirrorDistroArchRelease(
    ...     warty_i386, pocket, warty_component)

    >>> warty_mirror = new_mirror.ensureMirrorDistroReleaseSource(
    ...     warty, pocket, warty_component)

    >>> new_mirror.source_releases.count()
    1
    >>> new_mirror.arch_releases.count()
    1

If we try to create another MirrorDistroArchRelease with the same arch release
and pocket, that method will simply return the existing one.

    >>> same_warty_i386_mirror = new_mirror.ensureMirrorDistroArchRelease(
    ...     warty_i386, pocket, warty_component)
    >>> same_warty_i386_mirror == warty_i386_mirror
    True

    >>> same_warty_mirror = new_mirror.ensureMirrorDistroReleaseSource(
    ...     warty, pocket, warty_component)
    >>> same_warty_mirror == warty_mirror
    True

It's also possible to delete a MirrorDistroArchRelease/MirrorDistroReleaseSource
if we find out their contents are not in a mirror where they used to be.

    >>> new_mirror.deleteMirrorDistroReleaseSource(
    ...     warty, pocket, warty_component)
    >>> new_mirror.deleteMirrorDistroArchRelease(
    ...     warty_i386, pocket, warty_component)

    >>> from canonical.database.sqlbase import flush_database_updates
    >>> flush_database_updates()
    >>> new_mirror.source_releases.count()
    0
    >>> new_mirror.arch_releases.count()
    0

From every distribution, you can easily get a list with its official ARCHIVE
or RELEASE mirrors. This is available through the archive_mirrors and 
release_mirrors properties of IDistribution.

    >>> [(mirror.name, mirror.speed.title, mirror.country.name) 
    ...  for mirror in ubuntu.archive_mirrors]
    [(u'archive-404-mirror', '2 Mbps', u'British Indian Ocean Territory'),
     (u'archive-mirror', '128 Kbps', u'Afghanistan'),
     (u'archive-mirror2', '128 Kbps', u'Antarctica')]

    >>> [(mirror.name, mirror.speed.title, mirror.country.name) 
    ...  for mirror in ubuntu.release_mirrors]
    [(u'releases-mirror', '2 Mbps', u'British Indian Ocean Territory'),
     (u'releases-mirror2', '2 Mbps', u'Germany'),
     (u'unreachable-mirror', '512 Kbps', u'British Indian Ocean Territory')]

The list of unofficial mirrors can easily be obtained, so that the
distribution owner can see them and mark the ones that should be official.

    >>> [(mirror.name, mirror.speed.title, mirror.country.name) 
    ...  for mirror in ubuntu.unofficial_mirrors]
    [(u'foo.bar.com-archive', '2 Mbps', u'Brazil'),
     (u'invalid-mirror', '2 Mbps', u'British Indian Ocean Territory')]

It's possible to retrieve a mirror by its name:

    >>> from zope.interface.verify import verifyObject
    >>> from canonical.launchpad.interfaces import IDistributionMirror
    >>> example_mirror = mirrorset.getByName('archive-mirror')
    >>> verifyObject(IDistributionMirror, example_mirror)
    True

    >>> print mirrorset.getByName('non-existent-mirror')
    None

Or by any of its URLs (HTTP, FTP or Rsync)
First we'll have to add some of this URLs to sample data:

    >>> from canonical.launchpad.ftests import login 
    >>> login("mark@hbd.com")
    >>> example_mirror.ftp_base_url = 'ftp://localhost/example-ftp'
    >>> example_mirror.rsync_base_url = 'rsync://localhost/example-rsync'
    >>> flush_database_updates()

The getBy*Url methods return the corresponding mirrors:

    >>> http_mirror = mirrorset.getByHttpUrl(
    ...     'http://localhost:11375/valid-mirror')

    >>> print mirrorset.getByHttpUrl('http://non-existent-url')
    None

    >>> ftp_mirror = mirrorset.getByFtpUrl('ftp://localhost/example-ftp')
    >>> ftp_mirror.has_ftp_or_rsync_base_url
    True

    >>> print mirrorset.getByFtpUrl('ftp://non-existent-url')
    None

    >>> rsync_mirror = mirrorset.getByRsyncUrl(
    ...     'rsync://localhost/example-rsync')
    >>> rsync_mirror.has_ftp_or_rsync_base_url
    True

    >>> print mirrorset.getByRsyncUrl('rsync://non-existent-url')
    None


Probing the mirrors
-------------------

The distributionmirror-prober script is used to check what a mirror contains
and when it was last updated. This script should run at least once a day, so
we know the information we display is always up to date.

This script will probe only official ARCHIVE or RELEASE mirrors that
weren't probed in the last 23 (the value of PROBE_INTERVAL) hours.

    >>> [mirror.name
    ...  for mirror in mirrorset.getMirrorsToProbe(MirrorContent.ARCHIVE)]
    [u'archive-404-mirror', u'archive-mirror', u'archive-mirror2']

    >>> [mirror.name
    ...  for mirror in mirrorset.getMirrorsToProbe(MirrorContent.RELEASE)]
    [u'releases-mirror', u'releases-mirror2', u'unreachable-mirror']

    >>> valid_mirror = mirrorset[1]
    >>> valid_mirror.name
    u'archive-mirror'
    >>> from StringIO import StringIO
    >>> log_file = StringIO()
    >>> log_file.write("Fake probe, nothing useful here.")
    >>> log_file.seek(0)
    >>> library_alias = getUtility(ILibraryFileAliasSet).create(
    ...     name='foo', size=len(log_file.getvalue()),
    ...     file=log_file, contentType='text/plain')
    >>> proberecord = valid_mirror.newProbeRecord(library_alias)

    >>> [mirror.name
    ...  for mirror in mirrorset.getMirrorsToProbe(MirrorContent.ARCHIVE)]
    [u'archive-404-mirror', u'archive-mirror2']

    >>> [mirror.name
    ...  for mirror in mirrorset.getMirrorsToProbe(MirrorContent.RELEASE)]
    [u'releases-mirror', u'releases-mirror2', u'unreachable-mirror']

    The getMirrorsToProbe() method also accepts a ignore_last_probe argument,
    that, if True, will ignore previous probe records for all mirrors.

    >>> mirrors = mirrorset.getMirrorsToProbe(
    ...     MirrorContent.ARCHIVE, ignore_last_probe=True)
    >>> [mirror.name for mirror in mirrors]
    [u'archive-404-mirror', u'archive-mirror', u'archive-mirror2']

If when we finish probing a mirror, that mirror doesn't have any
MirrorDistroReleaseSource or MirrorDistroArchRelease, that mirror is marked as
disabled and a notification is sent to its owner and to the distribution's
mirror admin. This is done using IDistributionMirror.disableAndNotifyOwner().
Disabling a mirror causes it not to show up on the public mirror listings.

    >>> valid_mirror.enabled
    True
    >>> valid_mirror.disableAndNotifyOwner()

    Commit, so the email is actually sent.
    >>> import transaction
    >>> transaction.commit()

    >>> import email
    >>> from canonical.launchpad.mail import stub
    >>> len(stub.test_emails)
    2
    >>> stub.test_emails.sort(lambda a, b: cmp(a[1], b[1])) # sort by to_addr
    >>> from_addr, to_addr, raw_message = stub.test_emails.pop()
    >>> msg = email.message_from_string(raw_message)
    >>> msg['To']
    'mark@hbd.com,karl@canonical.com'
    >>> from_addr, to_addr, raw_message = stub.test_emails.pop()
    >>> msg = email.message_from_string(raw_message)
    >>> msg['To']
    'Mark Shuttleworth <mark@hbd.com>'
    >>> valid_mirror.enabled
    False

    Enable the mirror again.
    >>> from canonical.launchpad.ftests import login
    >>> valid_mirror.enabled = True

    Now we delete the MirrorProbeRecord we've just created, to make
    sure this mirror is probed by our prober script.
    >>> from zope.security.proxy import removeSecurityProxy
    >>> naked_record = removeSecurityProxy(proberecord)
    >>> naked_record.destroySelf()
    >>> flush_database_updates()
    >>> transaction.commit()


- Checking what content a mirror should contain

After obtaining the list of mirrors that we need to probe, the script will
then check what content is mirrored in each mirror. This is done by checking
the existence of some control files on that mirror. 

For Archive mirrors, these files are Packages.gz (one file per 
[arch_release, component, pocket] tuple) and Sources.gz (one per 
[release, component, pocket] tuple). The paths to these files are given
by the getExpectedPackagesPaths() and getExpectedSourcesPaths() methods of
IDistributionMirror.

    >>> paths = mirror.getExpectedPackagesPaths()
    >>> [path for (release, pocket, component, path) in paths 
    ...  if 'hoary' in path]
    [u'dists/hoary/main/binary-i386/Packages.gz',
     u'dists/hoary/restricted/binary-i386/Packages.gz',
     u'dists/hoary-backports/main/binary-i386/Packages.gz',
     u'dists/hoary-backports/restricted/binary-i386/Packages.gz',
     u'dists/hoary-security/main/binary-i386/Packages.gz',
     u'dists/hoary-security/restricted/binary-i386/Packages.gz',
     u'dists/hoary-updates/main/binary-i386/Packages.gz',
     u'dists/hoary-updates/restricted/binary-i386/Packages.gz',
     u'dists/hoary-proposed/main/binary-i386/Packages.gz',
     u'dists/hoary-proposed/restricted/binary-i386/Packages.gz']

    >>> paths = mirror.getExpectedSourcesPaths()
    >>> [path for (release, pocket, component, path) in paths
    ...  if 'hoary' in path]
    [u'dists/hoary/main/source/Sources.gz',
     u'dists/hoary/restricted/source/Sources.gz',
     u'dists/hoary-backports/main/source/Sources.gz',
     u'dists/hoary-backports/restricted/source/Sources.gz',
     u'dists/hoary-security/main/source/Sources.gz',
     u'dists/hoary-security/restricted/source/Sources.gz',
     u'dists/hoary-updates/main/source/Sources.gz',
     u'dists/hoary-updates/restricted/source/Sources.gz',
     u'dists/hoary-proposed/main/source/Sources.gz',
     u'dists/hoary-proposed/restricted/source/Sources.gz']

For Release mirrors, these files are listed in a file stored in
http://releases.ubuntu.com/. This file is parsed by
get_expected_cdimage_paths(), which returns a list of 
(distrorelease, flavour name, path) elements.
(For testing we have a sample of that file stored in our tree, which is
pointed by the config.distributionmirrorprober.releases_file_list_url option)

    >>> from canonical.launchpad.scripts.distributionmirror_prober import (
    ...     get_expected_cdimage_paths)
    >>> for (dummy, dummy, paths) in sorted(get_expected_cdimage_paths()):
    ...     for path in paths:
    ...         if '5.04' in path:
    ...             print path
    /kubuntu/hoary/kubuntu-5.04-install-amd64.iso
    /kubuntu/hoary/kubuntu-5.04-install-i386.iso
    /kubuntu/hoary/kubuntu-5.04-install-powerpc.iso
    /kubuntu/hoary/kubuntu-5.04-live-amd64.iso
    /kubuntu/hoary/kubuntu-5.04-live-i386.iso
    /kubuntu/hoary/kubuntu-5.04-live-powerpc.iso
    /hoary/ubuntu-5.04-install-amd64.iso
    /hoary/ubuntu-5.04-install-i386.iso
    /hoary/ubuntu-5.04-install-powerpc.iso
    /hoary/ubuntu-5.04-live-amd64.iso
    /hoary/ubuntu-5.04-live-i386.iso
    /hoary/ubuntu-5.04-live-powerpc.iso


- Checking how up-to-date the content is

After knowing what content a mirror is expected to contain, we need to check
when that mirror last synced its contents. 

To do that we use the getURLsToCheckUpdateness() of either
MirrorDistroReleaseSource or MirrorDistroArchRelease. This method returns a
dictionary mapping MirrorStatuses to URLs on that mirror. 

The prober will then check, between all reachable URLs, which one has the
status which corresponds to the most recent sync, and then set that as the
mirror's status.

On the warty release, component 'main' and pocket RELEASE , we had two uploads
between 2005-09-15 and 2005-09-17, so at that time we could've checked if 
that mirror's last sync was in the last one or two days.

    >>> import pytz
    >>> utc = pytz.timezone('UTC')
    >>> when = datetime(2005, 9, 17, tzinfo=utc)
    >>> urls = warty_mirror.getURLsToCheckUpdateness(when=when)
    >>> [(status.name, url) for (status, url) in urls.items()]
    [('UP',
      u'http://foo.bar.com/pub/pool/main/a/alsa-utils/alsa-utils_1.0.9a-4.dsc'),
     ('TWODAYSBEHIND',
      u'http://foo.bar.com/pub/pool/main/a/alsa-utils/alsa-utils_1.0.8-1ubuntu1.dsc')]

But if we were to check that mirror today, we could only check if the last
upload was mirrored and then mark the mirror as up-to-date. This is because
there were no recent uploads there.

    >>> urls = warty_mirror.getURLsToCheckUpdateness()
    >>> [(status.name, url) for (status, url) in urls.items()]
    [('UP', u'http://foo.bar.com/pub/pool/main/a/alsa-utils/alsa-utils_1.0.9a-4.dsc')]

If the mirror has no HTTP base url, we'll use the FTP one.

    >>> naked_mirror = removeSecurityProxy(warty_mirror)
    >>> http_url = naked_mirror.distribution_mirror.http_base_url
    >>> naked_mirror.distribution_mirror.http_base_url = None
    >>> naked_mirror.distribution_mirror.ftp_base_url = 'ftp://foo.bar.com/pub'
    >>> urls = warty_mirror.getURLsToCheckUpdateness()
    >>> [(status.name, url) for (status, url) in urls.items()]
    [('UP', u'ftp://foo.bar.com/pub/pool/main/a/alsa-utils/alsa-utils_1.0.9a-4.dsc')]
    >>> naked_mirror.distribution_mirror.http_base_url = http_url

The same goes for the warty i386 mirror, in which we had one upload on
2005-06-18 and two others on 2005-06-20. One slightly difference in this case
is that one of the uploads made on 2005-06-20 contains an .udeb package
instead of a .deb, and we don't check .udeb files on the mirror, so we need to
skip that upload.

    >>> from canonical.database.sqlbase import sqlvalues
    >>> from canonical.launchpad.database import (
    ...     BinaryPackageFile, SecureBinaryPackagePublishingHistory)

    >>> warty_i386_mirror = removeSecurityProxy(warty_i386_mirror)
    >>> recent_status, threshold = warty_i386_mirror.status_times[0]
    >>> start = datetime(2005, 06, 20, tzinfo=utc)
    >>> end = datetime(2005, 06, 20, tzinfo=utc) + timedelta(hours=0.5)
    >>> time_interval = (start, end)
    >>> upload = warty_i386_mirror.getLatestPublishingEntry(
    ...     time_interval, deb_only=False)

    >>> bpf = BinaryPackageFile.selectOneBy(
    ...     binarypackagereleaseID=upload.binarypackagerelease.id)
    >>> upload.binarypackagerelease.version, bpf.filetype.title
    (u'3.14156', 'UDEB Format')

    >>> when = datetime(2005, 6, 22, tzinfo=utc)
    >>> urls = warty_i386_mirror.getURLsToCheckUpdateness(when=when)
    >>> [(status.name, url) for (status, url) in urls.items()]
    [('UP',
      u'http://foo.bar.com/pub/pool/main/p/pmount/pmount_1.9-1_all.deb'),
     ('ONEWEEKBEHIND',
      u'http://foo.bar.com/pub/pool/main/m/mozilla-firefox/mozilla-firefox_0.9_i386.deb')]

    >>> when = datetime(2005, 6, 20, 0, 1, tzinfo=utc)
    >>> urls = warty_i386_mirror.getURLsToCheckUpdateness(when=when)
    >>> [(status.name, url) for (status, url) in urls.items()]
    [('UP', 
      u'http://foo.bar.com/pub/pool/main/p/pmount/pmount_1.9-1_all.deb'),
     ('TWODAYSBEHIND',
      u'http://foo.bar.com/pub/pool/main/m/mozilla-firefox/mozilla-firefox_0.9_i386.deb')]

If the mirror has no HTTP base url, we'll use the FTP one.

    >>> naked_mirror = removeSecurityProxy(warty_i386_mirror)
    >>> http_url = naked_mirror.distribution_mirror.http_base_url
    >>> naked_mirror.distribution_mirror.http_base_url = None
    >>> naked_mirror.distribution_mirror.ftp_base_url = 'ftp://foo.bar.com/pub'
    >>> urls = warty_i386_mirror.getURLsToCheckUpdateness()
    >>> [(status.name, url) for (status, url) in urls.items()]
    [('UP', u'ftp://foo.bar.com/pub/pool/main/l/linux-source-2.6.15/linux-2.6.12_2.6.12.20_i386.deb')]
    >>> naked_mirror.distribution_mirror.http_base_url = http_url


Running the prober script
-------------------------

First we need to run the http server that's going to answer our requests.

    >>> from canonical.launchpad.daemons.tachandler import TacTestSetup
    >>> from canonical.launchpad.scripts.ftests.test_distributionmirror_prober \
    ...     import HTTPServerTestSetup
    >>> http_server = HTTPServerTestSetup()
    >>> http_server.setUp()

Now we run the prober as another process, and check that the generated output
doesn't contain any errors and that the number of mirrors probed is correct.

    >>> import subprocess
    >>> cmd = 'cronscripts/distributionmirror-prober.py --content-type=archive'
    >>> prober = subprocess.Popen(
    ...     cmd, shell=True,stdin=subprocess.PIPE, stdout=subprocess.PIPE,
    ...     stderr=subprocess.PIPE)
    >>> stdout, stderr = prober.communicate()
    >>> print stdout
    <BLANKLINE>
    >>> print stderr
    INFO    Probing Archive Mirrors
    INFO    Probed 3 mirrors.
    INFO    Disabled 1 mirror(s) that were previously enabled.
    INFO    Done.
    <BLANKLINE>

    >>> cmd = 'cronscripts/distributionmirror-prober.py --content-type=release'
    >>> prober = subprocess.Popen(
    ...     cmd, shell=True,stdin=subprocess.PIPE, stdout=subprocess.PIPE,
    ...     stderr=subprocess.PIPE)
    >>> stdout, stderr = prober.communicate()
    >>> print stdout
    <BLANKLINE>
    >>> print stderr
    INFO    Probing Release Mirrors
    INFO    Probed 3 mirrors.
    INFO    Disabled 1 mirror(s) that were previously enabled.
    INFO    Done.
    <BLANKLINE>

    If we run the prober again, it won't do anything, because it will realize
    that the mirrors were probed recently, and, by default, don't need to be
    probed again.

    >>> prober = subprocess.Popen(
    ...     cmd, shell=True,stdin=subprocess.PIPE, stdout=subprocess.PIPE,
    ...     stderr=subprocess.PIPE)
    >>> stdout, stderr = prober.communicate()
    >>> print stdout
    <BLANKLINE>
    >>> print stderr
    INFO    Probing Release Mirrors
    INFO    No mirrors to probe.
    INFO    Done.
    <BLANKLINE>

    But we can override the default behaviour and tell the prober to check all
    official mirrors independently if they were probed recently or not.

    >>> cmd += ' --force'
    >>> prober = subprocess.Popen(
    ...     cmd, shell=True,stdin=subprocess.PIPE, stdout=subprocess.PIPE,
    ...     stderr=subprocess.PIPE)
    >>> stdout, stderr = prober.communicate()
    >>> print stdout
    <BLANKLINE>
    >>> print stderr
    INFO    Probing Release Mirrors
    INFO    Probed 3 mirrors.
    INFO    Done.
    <BLANKLINE>

    When a mirror is not reachabe or fail to mirror the content that it
    should, it's marked as disabled (as you can see above) and thus not
    shown on the public mirror listings. We'll keep probing these disabled
    mirrors and once they're reachabe and don't fail the content check
    we'll enable them again.

    >>> release_mirror = mirrorset.getByName('releases-mirror')
    >>> release_mirror.enabled
    True
    >>> release_mirror.enabled = False
    >>> flush_database_updates()
    >>> transaction.commit()
    >>> prober = subprocess.Popen(
    ...     cmd, shell=True,stdin=subprocess.PIPE, stdout=subprocess.PIPE,
    ...     stderr=subprocess.PIPE)
    >>> stdout, stderr = prober.communicate()
    >>> print stderr
    INFO    Probing Release Mirrors
    INFO    Probed 3 mirrors.
    INFO    Enabled 1 mirror(s) that were previously disabled.
    INFO    Done.
    <BLANKLINE>

    >>> from canonical.database.sqlbase import flush_database_caches
    >>> flush_database_caches()
    >>> release_mirror.enabled
    True

    >>> http_server.tearDown()
    >>> transaction.commit()

    >>> [(mirror.name, mirror.speed.title, mirror.country.name) 
    ...  for mirror in ubuntu.disabled_mirrors]
    [(u'archive-404-mirror', '2 Mbps', u'British Indian Ocean Territory'),
     (u'unreachable-mirror', '512 Kbps', u'British Indian Ocean Territory')]


Mirror content
--------------

Now that we've probed some mirrors, we can check the content that was found in
them.

First, let's check the source and arch releases of one archive mirror.

    >>> archive_mirror = mirrorset.getByName('archive-mirror')
    >>> archive_mirror.name
    u'archive-mirror'

    >>> mirror_arch_releases = (
    ...     archive_mirror.getSummarizedMirroredArchReleases())

    (We only have a few publishing records, so most of the release mirrors
     will have Unknown as their statuses)
    >>> for mirror_arch_release in mirror_arch_releases:
    ...     print (mirror_arch_release.distro_arch_release.displayname,
    ...            mirror_arch_release.status.title)
    (u'warty i386', 'Up to date')

    >>> mirror_source_releases = (
    ...     archive_mirror.getSummarizedMirroredSourceReleases())
    >>> for mirror_source_release in mirror_source_releases:
    ...     print (mirror_source_release.distrorelease.displayname,
    ...            mirror_source_release.status.title)
    (u'Warty', 'Up to date')
    (u'Hoary', 'Up to date')

Because all MirrorDistroArchReleases and MirrorDistroReleaseSources of this
mirror have 'Up to date' as status, this mirror's overall status will also be
'Up to date'.

    >>> archive_mirror.getOverallStatus().title
    'Up to date'


Now we check the MirrorCDImageDistroReleases of a release mirror.

    >>> release_mirror.name
    u'releases-mirror'

    >>> mirrored_releases = []
    >>> for mirror_cdimage_release in release_mirror.cdimage_releases:
    ...     mirrored_releases.append(
    ...         (mirror_cdimage_release.distrorelease.displayname,
    ...          mirror_cdimage_release.flavour))
    >>> [release for release in sorted(mirrored_releases)]
    [(u'Hoary', u'kubuntu'), (u'Hoary', u'ubuntu'), (u'Warty', u'ubuntu')]


In the case of release mirrors, they're said to be up-to-date if they
mirror all ISO images contained in http://releases.ubuntu.com, which is
the case here.  Otherwise, their status is unknown.

    >>> release_mirror.getOverallStatus().title
    'Up to date'
