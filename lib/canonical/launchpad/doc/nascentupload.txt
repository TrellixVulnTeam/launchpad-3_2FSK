== NascentUpload ==

Import the test keys so we have them ready for verification

  >>> from canonical.launchpad.ftests import import_public_test_keys
  >>> import_public_test_keys()

We need to be logged into the security model in order to get any further

  >>> login('foo.bar@canonical.com')

For the purpose of this test, hoary needs to be an open (development)
distrorelease so that we can upload to it.

  >>> from canonical.launchpad.interfaces import IDistributionSet
  >>> ubuntu = getUtility(IDistributionSet)['ubuntu']
  >>> hoary = ubuntu['hoary']
  >>> from canonical.lp.dbschema import DistributionReleaseStatus
  >>> hoary.releasestatus = DistributionReleaseStatus.DEVELOPMENT

A NascentUpload is a collection of files in a directory. They
represent what may turn out to be an acceptible upload to a launchpad
managed archive.

  >>> from canonical.archivepublisher.nascentupload import NascentUpload
  >>> from canonical.archivepublisher.tests import (
  ...    datadir, getPolicy, mock_logger, mock_logger_quiet)

  >>> buildd_policy = getPolicy(
  ...     name='buildd', distro='ubuntu', distrorelease='hoary', buildid=1)

  >>> sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distrorelease='hoary')

  >>> insecure_policy = getPolicy(
  ...     name='insecure', distro='ubuntu', distrorelease='hoary')


== Constructing a NascentUpload object ==

Constructing a NascentUpload instance verifies that the changes file
specified exists and tries to build a ChangeFile (see
doc/nascentuploadfile.txt) object based on that. If anything goes
wrong during this process FatalUploadError is raised:

  >>> NascentUpload(datadir("DOES-NOT-EXIST"), buildd_policy, mock_logger)
  Traceback (most recent call last):
  ...
  FatalUploadError:...

Otherwise a NascentFile containing a ChangesFile is ready to use.

  >>> quodlibet = NascentUpload(
  ...     datadir("quodlibet_0.13.1-1_i386.changes"),
  ...     buildd_policy, mock_logger_quiet)

  >>> quodlibet.changes
  <canonical.archivepublisher.changesfile.ChangesFile ...>


== NascentUpload Processing ==

Processing a NascentUpload consists of building files objects for each
specified file in the upload, executing all their specific checks and
collect all errors that may be generated. (see doc/nascentuploadfile.txt)

  >>> quodlibet.process()
  >>> for f in quodlibet.changes.files:
  ...     print f.filename, f
  quodlibet_0.13.1-1_all.deb <...DebBinaryUploadFile...>
  quodlibet-ext_0.13.1-1_i386.deb <...DebBinaryUploadFile...>

After that there are also some overall_checks which helps to
investigate if the files contained in the uploads have a sane
relationship.


=== Sourceful Uploads ===

We can check if the uploads contents are 'sourceful' (contains source
files) or 'binaryful' (contain binary files):

  >>> quodlibet.sourceful
  False
  >>> quodlibet.binaryful
  True

We can distinguish between the arch-indep and arch-dep binary uploads
and therefore check if it matches what is described in the changesfiles:

  >>> quodlibet.archdep
  True
  >>> quodlibet.archindep
  True


The same happens for source uploads, where we can identify if a source
is 'native' (only a TARBALL, no diff + orig) or 'has_orig' (uses ORIG
+ DIFF source form).

  >>> ed_source_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes.source-only-unsigned"),
  ...     sync_policy, mock_logger_quiet)

  >>> ed_source_upload.process()
  >>> for f in ed_source_upload.changes.files:
  ...     print f.filename, f
  ed_0.2-20.dsc <...DSCFile...>
  ed_0.2-20.diff.gz <...SourceUploadFile...>
  ed_0.2.orig.tar.gz <...SourceUploadFile...>

ed_source upload is *sourceful*:

  >>> ed_source_upload.sourceful
  True
  >>> ed_source_upload.binaryful
  False

ed_source is uses ORIG + DIFF form:

  >>> ed_source_upload.native
  False
  >>> ed_source_upload.hasorig
  True

For *sourceful* uploads 'archdep' and 'archindep' are always False:

  >>> ed_source_upload.archdep
  False
  >>> ed_source_upload.archindep
  False


=== Binaryful Uploads ===

Let's try a simple binary upload:

  >>> ed_binary_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes.binary-only-unsigned"),
  ...     buildd_policy, mock_logger_quiet)

  >>> ed_binary_upload.process()
  >>> for f in ed_binary_upload.changes.files:
  ...     print f.filename, f
  ed_0.2-20_i386.deb <...DebBinaryUploadFile...>

ed_binary is *binaryful*:

  >>> ed_binary_upload.sourceful
  False
  >>> ed_binary_upload.binaryful
  True

ed_binary contains only one 'architecture dependent binary':

  >>> ed_binary_upload.archdep
  True
  >>> ed_binary_upload.archindep
  False

As expected 'native' and 'hasorig' doesn't make any sense for binary
uploads, so they are alway False:

  >>> ed_binary_upload.native
  False
  >>> ed_binary_upload.hasorig
  False


Other Changesfile information are also checked across the uploads
files specified. For instance, the changesfile Architecture list line
should match the the files target architectures:

XXX cprov 20070404: we need to a policy that accepts unsigned
changesfiles and binary, source and mixed uploads ...

  >>> modified_buildd_policy = getPolicy(
  ...     name='buildd', distro='ubuntu', distrorelease='hoary', buildid=1)
  >>> modified_buildd_policy.can_upload_source = True
  >>> modified_buildd_policy.can_upload_mixed = True


  >>> ed_mismatched_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes.mismatched-arch-unsigned"),
  ...     modified_buildd_policy, mock_logger_quiet)

  >>> ed_mismatched_upload.process()

  >>> for f in ed_mismatched_upload.changes.files:
  ...     print f.filename, f
  ed_0.2-20.dsc <...DSCFile...>
  ed_0.2-20.diff.gz <...SourceUploadFile...>
  ed_0.2-20_i386.deb <...DebBinaryUploadFile...>

  >>> [a for a in ed_mismatched_upload.changes.architectures]
  ['source', 'amd64']

Since the changesfile specify that only 'source' (pseudo-architecture
to represent source in debian format) and 'amd64' will be used and
there is a file that depends on 'i386' the upload is rejected:

  >>> print ed_mismatched_upload.rejection_message
  ed_0.2-20_i386.deb: control file lists arch as 'i386' which isn't in the changes file.


=== Mixed Uploads ===

Uploads can also contain sources and binaries together and we call it
'mixed' mode. This feature is specially useful for uploading security
fixed into ubuntu since they are assembled and built in a external
system.

XXX cprov 20070404: we need a policy that accepts mixed uploads to
RELEASE pocket ...

  >>> modified_insecure_policy = getPolicy(
  ...     name='insecure', distro='ubuntu', distrorelease='hoary')
  >>> modified_insecure_policy.can_upload_binaries = True
  >>> modified_insecure_policy.can_upload_mixed = True

  >>> ed_mixed_upload = NascentUpload(
  ...     datadir("ed_0.2-20_i386.changes"),
  ...     modified_insecure_policy, mock_logger_quiet)

  >>> ed_mixed_upload.process()
  >>> ed_mixed_upload.is_rejected
  False

The NascentUpload can tell us if it is sourceful or not, (ditto binaryful)

  >>> ed_mixed_upload.sourceful
  True
  >>> ed_mixed_upload.binaryful
  True

Also provide architeture dependent status:

  >>> ed_mixed_upload.archindep
  False
  >>> ed_mixed_upload.archdep
  True

This mixed upload explores another feature in Soyuz, it does not
upload the ORIG files assuming it is already published by its
ancestries (it saves a lot of bandwidth). So, the upload is not
'native', neither 'hasorig':

  >>> ed_mixed_upload.native
  False
  >>> ed_mixed_upload.hasorig
  False

But if we check the DSC we will find the reference to the already
known ORIG file:

  >>> [f.filename for f in ed_mixed_upload.changes.dsc.files]
  ['ed_0.2.orig.tar.gz', 'ed_0.2-20.diff.gz']

  >>> success, msgs = ed_mixed_upload.do_accept()
  >>> success
  True


Briefly check the notification message generated by the mixed upload
(see more details in doc/nascentupload-announcements.txt)

  >>> len(msgs)
  1
  >>> print msgs[0]
  From: Root <root@localhost>
  To: Foo Bar <foo.bar@canonical.com>
  Bcc: Root <root@localhost>
  Precedence: bulk
  Subject: ed_0.2-20_i386.changes is NEW
  <BLANKLINE>
  NEW: ed_0.2-20.dsc
   OK: ed_0.2-20.diff.gz
  NEW: ed_0.2-20_i386.deb
  ...


Roll back everything related with ed_mixed_upload:

  >>> import transaction
  >>> transaction.abort()


== Acceptance Work-flow ==

The NascentUpload.do_accept method is the code with effectivelly adds
information to the database. Respective DistroReleaseQueue,
SourcePackageRelease, Build and BinaryPackageRelease will only exist
after calling this method.

First up, construct an upload of just the ed source...

  >>> ed_src = NascentUpload(
  ...     datadir('split-upload-test/ed_0.2-20_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> ed_src.process()
  >>> ed_src.is_rejected
  False
  >>> success, msgs = ed_src.do_accept()
  >>> success
  True

=== SourcePackageRelease Details ===

Retrive the just-inserted SourcePackageRelease correspondent to 'ed'

  >>> ed_spr = ed_src.queue_root.sources[0].sourcepackagerelease

Check if we have rebuid the change's author line properly (as
mentioned in bug # 30621)

  >>> print ed_spr.changelog
  ed (0.2-20) unstable; urgency=low
  ...
   -- James Troup <james@nocrew.org>  Wed,  2 Apr 2003 17:19:47 +0100

Some new fields required for NoMoreAptFtparchive implementation are
present in SourcePackageRelease. They are cached from the DSC and used
for the archive index generation:

The 'Maintainer:' identity in RFC-822 format, as it was in DSC:

  >>> ed_spr.dsc_maintainer_rfc822
  u'James Troup <james@nocrew.org>'

Version of debian policy/standards used to build this sourcepackage:

  >>> ed_spr.dsc_standards_version
  u'3.5.8.0'

Format of the included DSC (.dsc) file:

  >>> ed_spr.dsc_format
  u'1.0'

Binaries names claimed to be resulted of this source, line with names
separated by space:

  >>> ed_spr.dsc_binaries
  u'ed'

The ed source would be in NEW, so punt it into accepted.

  >>> ed_src.queue_root.setAccepted()
  >>> from canonical.launchpad.ftests import syncUpdate
  >>> syncUpdate(ed_src.queue_root)


=== Refuse to ACCEPT duplicated sources ===

Check if we refuse duplicated uploads even before publishing (bug #31038)
The uploaded source will be considered okay, since it still passing
all the consistency checks.

However there is another candidate, submitted before and not yet
published in the archive, which provides the same sourcepackagename
and sourcepackageversion for the distrorelease in question.

  >>> ed_src_dup = NascentUpload(
  ...     datadir('split-upload-test/ed_0.2-20_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> ed_src_dup.process()
  >>> ed_src_dup.is_rejected
  False

This is a special trick to make do_accept() consider this upload OLD
(publication already present in the archive), so it will try to
automatically promote the queue entry to ACCEPTED.

  >>> for upload_file in ed_src_dup.changes.files:
  ...     upload_file.new = False

The we invoke do_accept() normally, since the upload is consistent.
but since the uniqueness check in IDRQ.setAccepted() has detected
another accepted candidate that conflicts with the proposed one.
The upload will be rejected.

  >>> success, msgs = ed_src_dup.do_accept()
  ERROR: BOOM:
  <BLANKLINE>
  >>> success
  False
  >>> ed_src_dup.is_rejected
  True

  >>> print ed_src_dup.rejection_message
  Exception while accepting: This sourcepackagerelease is already accepted in hoary.

We rely on process-upload transaction rollback to not store bogus
queue entry in the database.

  >>> from canonical.lp.dbschema import DistroReleaseQueueStatus
  >>> hoary.getQueueItems(DistroReleaseQueueStatus.NEW).count()
  1


=== Building From ACCEPTED queue ===

XXX cprov 20060728: Building from ACCEPTED is special condition, not
really used in production. We should remove the support for this use
case, see further info in bug #55774.

Next we send in the binaries, since the source should be in ACCEPTED the
binary should go straight there too. Note that we are not specifying
any build, so it should be created apropriately, it is what happens
with staged security uploads:

XXX cprov 20070404: we are using a modified sync policy because we
need unsigned changes and binaries uploads (same as security, but also
accepts non-security uploads)

  >>> modified_sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distrorelease='hoary')
  >>> modified_sync_policy.can_upload_binaries = True

  >>> ed_bin = NascentUpload(
  ...      datadir('split-upload-test/ed_0.2-20_i386.changes'),
  ...      modified_sync_policy, mock_logger_quiet)

  >>> ed_bin.process()
  >>> ed_bin.is_rejected
  False

  >>> success, msgs = ed_bin.do_accept()

  >>> ed_bin.queue_root.status.name
  'NEW'

A build was created to represent the relationship between ed_src
(waiting in ACCEPTED queue) and the just uploaded ed_bin:

  >>> ed_build = ed_bin.queue_root.builds[0].build

  >>> ed_spr.id  == ed_build.sourcepackagerelease.id
  True

  >>> ed_build.title
  u'i386 build of ed 0.2-20 in ubuntu hoary RELEASE'

  >>> ed_build.buildstate.name
  'FULLYBUILT'



=== Staged Source and Binary upload with multiple binaries ===


As we could see both, sources and binaries, get into Launchpad via
nascent-upload infrastructure, i.e., both are processed as 'uploads'.

However in Launchpad the the package lifecyle can be described in 4
different stages:

 1. Source upload                     DRQ->DRQS->SPR
 2. Source queue acceptation          pending SSPPH
 3. Source publication                published SSPPH
 4. Build creation                    needsbuild Build
 5. Build dispatching                 building Build
 6. Build gathering & Binary upload   fullybuilt Build + DRQ->DRQB->BPR
 7. Binary queue acceptation          pending SBPPH
 8. Binary publication                published SBPPH

We will try to simulate this this procedure for a source upload that
produces multiple binaries using sync policy:

  >>> sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distrorelease='hoary')

Upload new source 'multibar', step 1:

  >>> multibar_src_upload = NascentUpload(
  ...     datadir('suite/multibar_1.0-1/multibar_1.0-1_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> multibar_src_upload.process()
  >>> success, msgs = multibar_src_upload.do_accept()
  >>> multibar_src_queue = multibar_src_upload.queue_root
  >>> multibar_src_queue.status.name
  'NEW'

  >>> multibar_src_queue.sources.count()
  1
  >>> multibar_spr = multibar_src_queue.sources[0].sourcepackagerelease
  >>> multibar_spr.title
  u'multibar - 1.0-1'

Once we have a new queue entry we are able to accept it, step 2:

  >>> multibar_src_queue.setAccepted()
  >>> syncUpdate(multibar_src_queue)
  >>> multibar_src_queue.status.name
  'ACCEPTED'


We can just just assume the source was published by step 3 for
simplicity and claim 'build from ACCEPTED' feature.

Build creation is done based on the SourcePackageRelease object, step 4:

  >>> from canonical.lp.dbschema import PackagePublishingPocket
  >>> multibar_build = multibar_spr.createBuild(
  ...     hoary['i386'], PackagePublishingPocket.RELEASE)

  >>> multibar_build.buildstate.name
  'NEEDSBUILD'

We have just created a pending build record for hoary/i386.

Now we also assume that the build was dispatched by the slave-scanner
script, step 5.

On step 6, the slave-scanner collect the files generated on builders
and organise them as an ordinary binary upload having a changesfile
and the collection of deb produced.

At this point slave-scanner move the upload to the appropriate path
(/srv/launchpad.net/builddmaster) and invoke process-upload.py with
the 'buildd' upload policy and the build record id.

  >>> buildd_policy = getPolicy(
  ...     name='buildd', distro='ubuntu', distrorelease='hoary',
  ...     buildid=multibar_build.id)

  >>> multibar_bin_upload = NascentUpload(
  ...     datadir('suite/multibar_1.0-1/multibar_1.0-1_i386.changes'),
  ...     buildd_policy, mock_logger_quiet)
  >>> multibar_bin_upload.process()
  >>> success, msgs = multibar_bin_upload.do_accept()


Now that we have successfully processed the binaries coming from a
builder, step 6, we can check the status of the database entities
related to it.

We have a NEW queue entry, containing the Build results:

  >>> multibar_bin_queue = multibar_bin_upload.queue_root
  >>> multibar_bin_queue.status.name
  'NEW'
  >>> multibar_bin_queue.builds.count()
  1

The build considered as 'producer' of the upload binaries is the same
that we have created in step 3:

  >>> build = multibar_bin_queue.builds[0].build
  >>> build.id == multibar_build.id
  True

Also the build record was updated to FULLYBUILT in nascentupload domain.

  >>> build.buildstate.name
  'FULLYBUILT'

After certifying that the build record is marked as FULLYBUILT the
slave-scanner can safely update the build information (buildlog,
duration, etc) and clean the builder for anther job.

If the build record was not marked as FULLYBUILT during the
upload-time, it means that the slave should be hold with the builds
results for later processing.

Updating the build record in upload-domain avoids possible
inconsistence when a binary upload was not processed correctly, then
was not stored in Launchpad database. The slave-scanner has no way to
recognise such situations easily, since process-upload exits with
success even when the upload is rejected. See bug #32261 for further info.

Chuck it all away again:

  >>> transaction.abort()


== Post-Release pockets uploads ==

And this time, try an upload to -updates, it'll have to be signed etc because
we're using the insecure policy to check everything in it end-to-end. We have
to set hoary to CURRENT in order to do this because we're not allowed
to upload to -UPDATES in a DEVELOPMENT release.

  >>> hoary.releasestatus = DistributionReleaseStatus.CURRENT

Note that the policy do not have fixed distrorelease, it will be
overriden by the changesfile:

  >>> norelease_sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu')

  >>> ed_src = NascentUpload(
  ...     datadir('updates-upload-test/ed_0.2-20_source.changes'),
  ...     norelease_sync_policy, mock_logger_quiet)
  >>> ed_src.process()
  >>> ed_src.is_rejected
  False

  >>> success, msgs = ed_src.do_accept()

  >>> print ed_src.queue_root.pocket.name
  UPDATES

Even though this went to a pocket and thus would be unapproved rather
than accepted, the ed upload ought still make it to NEW instead of
unapproved.

  >>> print ed_src.queue_root.status.name
  NEW

And pop it back to development now that we're done

  >>> hoary.releasestatus = DistributionReleaseStatus.DEVELOPMENT

Check the uploader behaviour against a missing orig.tar.gz file,
bug # 30741.

  >>> ed21_src = NascentUpload(
  ...     datadir('ed-0.2-21/ed_0.2-21_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> ed21_src.process()
  >>> ed21_src.is_rejected
  True
  >>> print ed21_src.rejection_message+"\nEND"
  Unable to find ed_0.2.orig.tar.gz in upload or distribution.
  Files specified in DSC are broken or missing, skipping package unpack verification.
  END

== Installer source uploads doesn't contain 'Standards-Version' ==

Check if we can accept a installer-source upload which doesn't have
'Standards-Version' field in DSC. See bug #75874 for further
information.

  >>> inst_src = NascentUpload(
  ...     datadir('test75874_0.1_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> inst_src.process()

  >>> inst_src.is_rejected
  False

  >>> success, msgs = inst_src.do_accept()
  >>> success
  True

Look for the respective SourcePackageRelease entry and inspect its
content, it should have all the required fields except the
'dsc_standards_version':

  >>> inst_queue = hoary.getQueueItems(DistroReleaseQueueStatus.NEW,
  ...                                  name='test75874', exact_match=True)[0]
  >>> inst_spr = inst_queue.sources[0].sourcepackagerelease

  >>> inst_spr.dsc_maintainer_rfc822
  u'Colin Watson <cjwatson@ubuntu.com>'

  >>> inst_spr.dsc_binaries
  u'test75874'

  >>> inst_spr.dsc_standards_version is None
  True

Chuck it all away again

  >>> transaction.abort()

== Insecure Policy ==

'insecure' upload policy forces NascentUpload to perform ACLs over the
DSC signature. It only allows 'source' upload where both, changesfile
and DSC, should be signed.

Import the test keys again since the transaction was aborted before.

  >>> from canonical.launchpad.ftests import import_public_test_keys
  >>> import_public_test_keys()

When using 'insecure' policy, NascentUpload instace stores the DSC
sigining key reference as an IGPGKey:

  >>> bar_ok = NascentUpload(
  ...     datadir('suite/bar_1.0-1/bar_1.0-1_source.changes'),
  ...     insecure_policy, mock_logger_quiet)
  >>> bar_ok.process()
  >>> bar_ok.is_rejected
  False

  >>> from zope.interface.verify import verifyObject
  >>> from canonical.launchpad.interfaces import (
  ...    IGPGKey, IPersonSet)

  >>> verifyObject(IGPGKey, bar_ok.changes.dsc.signingkey)
  True

  >>> verifyObject(IGPGKey, bar_ok.changes.signingkey)
  True

The second key of name16 person is used to sign uploads (the first gpgkey
record is a placeholder one, we used the second key):

  >>> name16 = getUtility(IPersonSet).getByName('name16')
  >>> uploader_key = name16.gpgkeys[1]

Both, DSC and changesfile were signed:

  >>> bar_ok.changes.dsc.signingkey.fingerprint == uploader_key.fingerprint
  True

  >>> bar_ok.changes.signingkey.fingerprint == uploader_key.fingerprint
  True

Let's modify the current ACL rules for ubuntu, moving the upload
rights to all commponents from 'ubuntu-team' to 'sabdfl':

  >>> new_uploader = getUtility(IPersonSet).getByName('sabdfl')
  >>> for distro_component in ubuntu.uploaders:
  ...     distro_component.uploader = new_uploader

This time the upload should fail because the ACLs don't let
"name16", the key owner, upload a package.

  >>> bar_failed = NascentUpload(
  ...     datadir('suite/bar_1.0-1/bar_1.0-1_source.changes'),
  ...     insecure_policy, mock_logger_quiet)

  >>> bar_failed.process()
  >>> bar_failed.is_rejected
  True
  >>> print bar_failed.rejection_message
  Signer has no upload rights at all to this distribution.

Even in a rejected upload using 'insecure' policy, the DSC signing key
and the changesfile sigining key are stored in NascentUpload instance
for further checks:

  >>> verifyObject(IGPGKey, bar_failed.changes.dsc.signingkey)
  True
  >>> verifyObject(IGPGKey, bar_failed.changes.signingkey)
  True

  >>> bar_failed.changes.dsc.signingkey.fingerprint == uploader_key.fingerprint
  True
  >>> bar_failed.changes.signingkey.fingerprint == uploader_key.fingerprint
  True


== DEB packages using BZIP ==

Deb packages can compress their contents in a bzip tar file. But
in these case, the control file should state that the package
Pre-depends on a newer version of dpkg. NascentUploadFile enforces
that constraint.

  >>> binary_sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distrorelease='hoary')
  >>> binary_sync_policy.can_upload_binaries = True
  >>> binary_sync_policy.can_upload_mixed = True

  >>> foo_failed = NascentUpload(
  ...     datadir('suite/foo_1.0-1_mixed/foo_1.0-1_i386.changes'),
  ...     binary_sync_policy, mock_logger_quiet)
  >>> foo_failed.process()

  >>> print foo_failed.rejection_message
  foo_1.0-1_i386.deb uses bzip2 compression but pre-depends on an old version of dpkg: 1.10.20


== Dealing with Epochs and diverging binary versions ==

Versions stored in Launchpad should include 'epoch'.

Let's process an source upload and ensure that the resulting
SourcePackageRelease record store a propoer 'version':

  >>> bar_src_upload = NascentUpload(
  ...     datadir('suite/bar_1.0-9/bar_1.0-9_source.changes'),
  ...     sync_policy, mock_logger_quiet)
  >>> bar_src_upload.process()
  >>> bar_src_upload.is_rejected
  False
  >>> success, msgs = bar_src_upload.do_accept()

For source uploads, Changes.version == DSC.version == SPR.version:

  >>> bar_src_upload.changes.version
  '1:1.0-9'

  >>> bar_src_upload.changes.dsc.dsc_version
  '1:1.0-9'

  >>> bar_src_queue = bar_src_upload.queue_root
  >>> bar_spr = bar_src_queue.sources[0].sourcepackagerelease
  >>> bar_spr.version
  u'1:1.0-9'


Let's accept the source and claim 'build from accepted' to process the
respective binary:

  >>> bar_src_queue.status.name
  'NEW'
  >>> bar_src_queue.setAccepted()
  >>> bar_src_queue.status.name
  'ACCEPTED'
  >>> syncUpdate(bar_src_queue)


We will use a modified Sync upload policy to upload unsigned binaries:

  >>> binary_sync_policy = getPolicy(
  ...     name='sync', distro='ubuntu', distrorelease='hoary')
  >>> binary_sync_policy.can_upload_binaries = True
  >>> binary_sync_policy.can_upload_mixed = True


For a binary upload we expect the same, a BinaryPackageRelease
'version' that includes 'epoch':

  >>> bar_bin_upload = NascentUpload(
  ...     datadir('suite/bar_1.0-9_binary/bar_1.0-9_i386.changes'),
  ...     binary_sync_policy, mock_logger_quiet)
  >>> bar_bin_upload.process()
  >>> bar_bin_upload.is_rejected
  False
  >>> success, msgs = bar_bin_upload.do_accept()
  >>> bar_bin_queue = bar_bin_upload.queue_root
  >>> bar_bin_queue.status.name
  'NEW'


The Changesfile version always refers to the source version and the
binary versions included in the upload can diverge between themselves
and from the source version.

  >>> bar_bin_upload.changes.version
  '1:1.0-9'

  >>> deb_file = bar_bin_upload.changes.files[0]
  >>> deb_file.filename
  'bar_6.6.6_i386.deb'

  >>> deb_file.version
  '1:1.0-9'

  >>> deb_file.source_version
  '1:1.0-9'

  >>> deb_file.control_version
  '1:6.6.6'

Anyway, the proper value for BinaryPackageRelease.version is the
version stored in the binary control file:

  >>> bar_bpr = bar_bin_queue.builds[0].build.binarypackages[0]
  >>> bar_bpr.version
  u'1:6.6.6'
