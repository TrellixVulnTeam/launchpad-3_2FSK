= Buildd Slave Scanner =

The Buildd Slave scanner is able to run over the build jobs being
processed in the current BuildFarm and collect information about the
status of the process, collect the results of finished jobs and
automatically dispatch new jobs to idle slaves.

    >>> from canonical.buildmaster.master import BuilddMaster

The Master side of Buildd requires access to Launchpad Database, the
user designed for this kind of access is 'fiera', as in all test the
transaction should be retrieved.

    >>> from canonical.database.sqlbase import ZopelessTransactionManager
    >>> local_transaction = ZopelessTransactionManager._installed

We check for sent mails in some places, so load the stub mailer:

    >>> from canonical.launchpad.mail import stub
    >>> from canonical.database.sqlbase import commit

And create a utility function to make tests easier to read.

    >>> def check_mail_sent(last_stub_mail_count):
    ...    commit()
    ...    return len(stub.test_emails) == last_stub_mail_count + 3

The master also requires an 'logging' instance to not compromise the
standard output with noisily output.

    >>> import logging

First let's test an essential part of the BuilddMaster class, the
BuilderGroup() class, by creating an empty BuilderGroup object

    >>> from canonical.buildmaster.buildergroup import BuilderGroup

    >>> buildergroup = BuilderGroup(
    ...     logging.getLogger(), local_transaction)

Import MockBuilder and a series of MockSlaves to be used in this test.

    >>> from canonical.launchpad.ftests.soyuzbuilddhelpers import (
    ...    AbortedSlave, AbortingSlave, BrokenSlave, BuildingSlave,
    ...    InsaneWaitingSlave, LostBuildingBrokenSlave,
    ...    LostBuildingSlave, LostWaitingSlave, MockBuilder, OkSlave,
    ...    SaneBuildingSlave, SaneWaitingSlave, WaitingSlave)

Let's play with a BuilderGroup method designed to rescue build slaves
that are processing unknown jobs. In real conditions, this situation
only happens if the slave is processing deleted or modified BuildQueue
entry, since Build entries are never removed. It might be caused by
exceptions in slavescanner or queuebuilder scripts.

When we figured this situation out, the procedure to rescue is to
request the slave XMLRPC method 'clean', reseting the slave completely.

We figured out if the building information is correct and sane by
checking the job identifier field from status message information,
which consists of "<Build.id>-<BuildQueue.id>".

First let's emulate a sane and a lost slave. The SaneSlave returns a
job identifier that exists in our sampledata, but the LostSlave
returns a completely bogus one.

The the mock slave.clean() method is modified to print a message for
testing purposes.

Initializing the sane_builder. It was not rescued, since the job
identifier is sane (Build.id == 8 and BuildQueue.id == 1 exist):

    >>> sanebuilding_builder = MockBuilder(
    ...     'Sane Building Slave', SaneBuildingSlave())
    >>> buildergroup.rescueBuilderIfLost(sanebuilding_builder) is None
    True

A sane WAITING slave:

    >>> sanewaiting_builder = MockBuilder(
    ...     'Sane Waiting Slave', SaneWaitingSlave())
    >>> buildergroup.rescueBuilderIfLost(sanewaiting_builder) is None
    True

A insane WAITING slave, with wrong BuildQueue/Build relation:

    >>> insanewaiting_builder = MockBuilder(
    ...     'Insane Waiting Slave', InsaneWaitingSlave())
    >>> buildergroup.rescueBuilderIfLost(insanewaiting_builder)
    WARNING:root:Builder 'Insane Waiting Slave' rescued from '7-1: Job build entry mismatch'

It was rescued because the BuildQueue.id == 1 isn't related to
Build.id == 7, so this pair relation is wrong.

Let's test slaves with job identifier pointing non-existent
Build/BuildQueue entries. first a lost slave in status 'BUILDING':

    >>> lostbuilding_builder = MockBuilder(
    ...     'Lost Building Slave', LostBuildingSlave())
    >>> buildergroup.rescueBuilderIfLost(lostbuilding_builder)
    WARNING:root:Builder 'Lost Building Slave' rescued from '1000-10000: 'The object Build by the ID 1000 does not exist''

Then a lost slave in status 'WAITING':

    >>> lostwaiting_builder = MockBuilder(
    ...     'Lost Waiting Slave', LostWaitingSlave())
    >>> buildergroup.rescueBuilderIfLost(lostwaiting_builder)
    WARNING:root:Builder 'Lost Waiting Slave' rescued from '1000-10000: 'The object Build by the ID 1000 does not exist''

Both got rescued, as expected.

Slave-scanner will deactivate a 'lost-building' builder that could not
be aborted appropriately.

    >>> lostbuilding_builder = MockBuilder(
    ...     'Lost Building Broken Slave', LostBuildingBrokenSlave())

    >>> from canonical.launchpad.interfaces import IDistributionSet
    >>> hoary_i386 = getUtility(IDistributionSet)['ubuntu']['hoary']['i386']
    >>> buildergroup.updateBuilderStatus(lostbuilding_builder, hoary_i386)
    WARNING:root:Lost Building Broken Slave (http://fake:0000) marked as failed due to: <Fault 8002: 'Could not abort'>
    Traceback (most recent call last):
    ...
    Fault: <Fault 8002: 'Could not abort'>

'ensurePresent()' slave method always return True, it theoretically
means the slave has the requested file in cache.

The mock slaves will also print, when necessary, whether it has been
passed an 'archives' property in the args dictionary.

The archives are passed from the buildmaster and controls what archives
exist in the apt sources.list.  If nothing is passed, the chroot's default
list applies, otherwise the passed list is used.  This behavior is required
in build slaves because some jobs may only depend on certain archives and
hence certain package dependencies.

    >>> builder1 = MockBuilder('Broken Slave', BrokenSlave())

    >>> builder2 = MockBuilder('Idle Slave', OkSlave())

    >>> builder3 = MockBuilder(
    ...    'Package Failed', WaitingSlave('BuildStatus.PACKAGEFAIL'))

    >>> builder4 = MockBuilder(
    ...     'Missing Dependency build',
    ...     WaitingSlave('BuildStatus.DEPFAIL', 'baz (>= 1.0.1)'))

    >>> builder5 = MockBuilder(
    ...     'Bad Chroot', WaitingSlave('BuildStatus.CHROOTFAIL'))

    >>> builder6 = MockBuilder(
    ...     'I am out of order', WaitingSlave('BuildStatus.BUILDERFAIL'))

    >>> builder7 = MockBuilder('I am busy', BuildingSlave())

    >>> builder8 = MockBuilder('I was aborted', AbortedSlave())

    >>> builder9 = MockBuilder(
    ...     'I am trying to terminate the child process', AbortingSlave())

    >>> builder10 = MockBuilder(
    ...     'Package Successfully Built',
    ...      WaitingSlave('BuildStatus.OK'))

    >>> builder11 = MockBuilder(
    ...     'I am giving this job back',
    ...     WaitingSlave('BuildStatus.GIVENBACK'))

    >>> buildergroup.builders = [
    ...     builder1, builder2, builder3, builder4, builder5, builder6,
    ...     builder7, builder8, builder9, builder10, builder11]

The slavescanner system also perform build-notification for the
following states: FAILEDTOBUILD and CHROOTWAIT

    >>> from canonical.launchpad.interfaces import IBuildSet, IBuilderSet
    >>> import datetime, pytz

    >>> UTC = pytz.timezone('UTC')

We want to get a Build and make BuildQueue items for it:

    >>> a_build = getUtility(IBuildSet).getByBuildID(8)

To make testing easier we provide a convenience function to put a BuildQueue
object into a preset fixed state:

    >>> default_start = datetime.datetime(2005, 1, 1, 8, 0, 0, tzinfo=UTC)
    >>> def setupBuildQueue(build_queue, builder):
    ...      build_queue.builder = builder
    ...      build_queue.buildstart = default_start

Remove any previous buildmaster ROOT directory, to avoid any garbage
lock conflict (it would be recreated automatically if necessary)

    >>> from canonical.config import config
    >>> import shutil
    >>> import os
    >>> if os.access(config.builddmaster.root, os.F_OK):
    ...     shutil.rmtree(config.builddmaster.root)

Let's check the procedures to verify/collect running build process:

  WAITING - PACKAGEFAIL -> Package has failed to build, notice from
  builder is stored, but Build.buildstate is mark as 'Failed to Build':

Get a builder from the sample data:

    >>> a_builder = getUtility(IBuilderSet).get(1)

Make sure that a_builder has no active builds:

    >>> if a_builder.currentjob is not None:
    ...     a_builder.currentjob.buildstart = None
    ...     a_builder.currentjob.builder = None

Force the test builder to be 'ok' as the code required to do this
automatically is not yet factored into the content class.

    >>> a_builder.builderok = True

Create a mock slave so the builder can operate - one with a failed package.

    >>> a_builder.setSlaveForTesting(WaitingSlave('BuildStatus.PACKAGEFAIL'))

    >>> bqItem3 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem3, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Do the test execution:

    >>> buildergroup.updateBuild(bqItem3)
    >>> bqItem3.build.builder is not None
    True
    >>> bqItem3.build.datebuilt is not None
    True
    >>> bqItem3.build.buildduration is not None
    True
    >>> bqItem3.build.buildlog is not None
    True
    >>> check_mail_sent(last_stub_mail_count)
    True
    >>> bqItem3.build.buildstate.title
    'Failed to build'

Cleanup in preparation for the next test:

    >>> bqItem3.destroySelf()

WAITING - DEPWAIT -> a required dependency is missing, again notice
from builder, but Build.buildstate has the right state:

    >>> bqItem4 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem4, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder can operate - one with a dependency error.

    >>> bqItem4.builder.setSlaveForTesting(
    ...                        WaitingSlave('BuildStatus.DEPFAIL',
    ...                                     'baz (>= 1.0.1)'))

Do the test execution:

    >>> buildergroup.updateBuild(bqItem4)
    CRITICAL:root:***** bob is MANUALDEPWAIT *****
    >>> bqItem4.build.builder is not None
    True
    >>> bqItem4.build.datebuilt is not None
    True
    >>> bqItem4.build.buildduration is not None
    True
    >>> bqItem4.build.buildlog is not None
    True
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> bqItem4.build.dependencies
    u'baz (>= 1.0.1)'
    >>> bqItem4.build.buildstate.title
    'Dependency wait'

Cleanup in preparation for the next test:

    >>> bqItem4.destroySelf()

WAITING - CHROOTFAIL -> the Chroot for this distroseries is damage, nor
builder, but right state stored in Build entry:

    >>> bqItem5 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem5, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

  Create a mock slave so the builder can operate - one with a failed chroot.

    >>> bqItem5.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.CHROOTFAIL'))
    >>> buildergroup.updateBuild(bqItem5)
    CRITICAL:root:***** bob is CHROOTWAIT *****
    >>> bqItem5.build.builder is not None
    True
    >>> bqItem5.build.datebuilt is not None
    True
    >>> bqItem5.build.buildduration is not None
    True
    >>> bqItem5.build.buildlog is not None
    True
    >>> check_mail_sent(last_stub_mail_count)
    True
    >>> bqItem5.build.buildstate.title
    'Chroot problem'

Cleanup in preparation for the next test:

    >>> bqItem5.destroySelf()

WAITING - BUILDERFAIL -> builder has failed by internal error, job is
available for next build round:

    >>> bqItem6 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem6, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder can operate - one with a builder error.

    >>> bqItem6.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.BUILDERFAIL'))

    >>> buildergroup.updateBuild(bqItem6)
    WARNING:root:***** bob has failed *****

    >>> from canonical.launchpad.ftests import sync
    >>> sync(a_builder)
    >>> a_builder.failnotes
    u'Builder returned BUILDERFAIL when asked for its status'

    >>> bqItem6.builder is None
    True
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> bqItem6.build.buildstate.title
    'Needs building'

Cleanup in preparation for the next test:

    >>> bqItem6.destroySelf()
    >>> a_builder.builderok = True


BUILDING -> builder still processing the job, simply collect the logtail:

    >>> bqItem7 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem7, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder can operate - one which is building.

    >>> bqItem7.builder.setSlaveForTesting(BuildingSlave())
    >>> builder_id = bqItem7.builder.id
    >>> buildergroup.updateBuild(bqItem7)

Due to updateBuild doing a commit we cannot compare the object instance.

    >>> bqItem7.builder.id is builder_id
    True
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> bqItem7.logtail
    u'This is a build log'

Cleanup in preparation for the next test:

    >>> bqItem7.destroySelf()

ABORTED -> builder was aborted, release builder and reset job for the
next build round:

    >>> bqItem8 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem8, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

    >>> bqItem8.builder.setSlaveForTesting(AbortedSlave())
    >>> bqItem8.builder.name
    u'bob'
    >>> buildergroup.updateBuild(bqItem8)
    >>> bqItem8.builder is None
    True

Cleanup in preparation for the next test:

    >>> bqItem8.destroySelf()

ABORTING -> builder is trying to terminate its children process, the
only action master can perform is polling the slave status until it
gets ABORTED.

    >>> bqItem9 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem9, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

    >>> bqItem9.builder.setSlaveForTesting(AbortingSlave())
    >>> bqItem9.builder.name
    u'bob'
    >>> buildergroup.updateBuild(bqItem9)
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> bqItem9.logtail
    u'Waiting for slave process to be terminated'

Cleanup in preparation for the next test:

    >>> bqItem9.destroySelf()


== Builder WAITING in OK state ==

This situation happens when the builder has finished the job and is
waiting for the master to collect its results.

The build record in question can end up in the following states:

 * FULLYBUILT: when binaries were collected and uploaded correctly;
 * FAILEDTOUPLOAD: binaries were collected but the upload was
                   rejected/failed.


=== Failed to Upload (FAILEDTOUPLOAD) ===


    >>> bqItem10 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem10, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem10.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.OK'))

If the build record wasn't updated before/during the updateBuild
(precisely on binary upload time), the build will be considered
FAILEDTOUPLOAD:

    >>> buildergroup.updateBuild(bqItem10)
    >>> bqItem10.build.builder is not None
    True
    >>> bqItem10.build.datebuilt is not None
    True
    >>> bqItem10.build.buildduration is not None
    True
    >>> bqItem10.build.buildlog is not None
    True
    >>> check_mail_sent(last_stub_mail_count)
    True
    >>> bqItem10.build.buildstate.title
    'Failed to upload'

Let's check the emails generated by this 'failure'
(see build-failedtoupload-workflow.txt for more information):

    >>> from canonical.launchpad.mail import stub
    >>> from operator import itemgetter
    >>> local_test_emails = stub.test_emails[last_stub_mail_count:]
    >>> local_test_emails.sort(key=itemgetter(1), reverse=True)
    >>> for from_addr, to_addrs, raw_msg in local_test_emails:
    ...      print to_addrs
    ['mark@hbd.com']
    ['foo.bar@canonical.com']
    ['celso.providelo@canonical.com']

Note that a real failed-to-upload notification contains the respective
upload log information:

    >>> one_email = stub.test_emails.pop()
    >>> from_addr, to_addrs, raw_msg = one_email
    >>> print raw_msg
    Content-Type: text/plain; charset="utf-8"
    ...
    X-Launchpad-Build-State: FAILEDTOUPLOAD
    ...
    * Build Log: http://localhost:58000/.../buildlog_ubuntu-hoary-i386.mozilla-=
    firefox_0.9_BUILDING.txt.gz
    ...
    Upload log:
    INFO    creating lockfile
    DEBUG   Initialising connection.
    ...
    DEBUG   Removing lock file: /var/lock/process-upload-buildd.lock
    ...

What we can clearly notice is that the buildlog is still containing
the old build state (BUILDING) in its name. This is a minor problem
that can be sorted by modifying the execution order of procedures
inside Buildergroup.buildStatus_OK method.

Cleanup in preparation for the next test:

    >>> bqItem10.destroySelf()


=== Successfully collected and uploaded  (FULLYBUILT) ===

Build item 6 has binary packages available in the sample data, letting us test
this case cleanly. We need to set the pocket to updates for this test as its
uploading to warty.

    >>> bqItem10 = getUtility(IBuildSet).getByBuildID(
    ...     6).createBuildQueueEntry()

XXX: The pocket attribute is not intended to be changed in regular code, but
for this test we want to change it on the fly. An alternative would be to add
new sample data for a build that can be uploaded with binary packages attached
to it.

    >>> from zope.security.proxy import removeSecurityProxy
    >>> from canonical.launchpad.interfaces import PackagePublishingPocket
    >>> removeSecurityProxy(
    ...     bqItem10.build).pocket = PackagePublishingPocket.UPDATES
    >>> setupBuildQueue(bqItem10, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem10.builder.setSlaveForTesting(WaitingSlave('BuildStatus.OK'))

Now in order to emulate a successfully binary upload we will update
the build record to FULLYBUILT, as the process-upload would do:

    >>> from canonical.launchpad.interfaces import BuildStatus
    >>> bqItem10.build.buildstate = BuildStatus.FULLYBUILT

Now the updateBuild should recognize this build record as a
Successfully built and uploaded procedure, not sending any
notification and updating the build information:

    >>> buildergroup.updateBuild(bqItem10)
    >>> bqItem10.build.builder is not None
    True
    >>> bqItem10.build.datebuilt is not None
    True
    >>> bqItem10.build.buildduration is not None
    True
    >>> bqItem10.build.buildlog is not None
    True
    >>> bqItem10.build.buildstate.title
    'Successfully built'
    >>> check_mail_sent(last_stub_mail_count)
    False

Cleanup in preparation for the next test:

    >>> bqItem10.destroySelf()

WAITING -> GIVENBACK - slave requested build record to be rescheduled.

    >>> bqItem11 = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(bqItem11, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem11.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.GIVENBACK'))
    >>> buildergroup.updateBuild(bqItem11)
    WARNING:root:***** 1-1 is GIVENBACK by bob *****

Ensure GIVENBACK build preserves the history for future use. (we
can't be sure if logtail will contain any information, because it
depends on how long the build took to be processed and how often we
scanned it)

    >>> bqItem11.builder is None
    True
    >>> bqItem11.buildstart is None
    True
    >>> bqItem11.lastscore
    0
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> bqItem11.build.buildstate.title
    'Needs building'

Cleanup in preparation for the next test:

    >>> bqItem11.destroySelf()

The Builddmaster should crash when collecting builds which are denied in
the given distroseries/pocket. Anytime it happens we need to manually
investigate why this build end up built. (should never happen in real
cases, and even so should be refused when we try to upload it.)


    >>> bqItem12 = getUtility(IBuildSet).getByBuildID(
    ...     2).createBuildQueueEntry()
    >>> setupBuildQueue(bqItem12, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem12.builder.setSlaveForTesting(WaitingSlave('BuildStatus.OK'))
    >>> buildergroup.updateBuild(bqItem12)
    Traceback (most recent call last):
    ...
    AssertionError: i386 build of mozilla-firefox 0.9 in ubuntu warty RELEASE (2) can not be built for pocket RELEASE: illegal status


The buildlog is collected and compressed locally using gzip algorithm,
let's see how this method works:

    >>> bqItem10.builder.setSlaveForTesting(WaitingSlave('BuildStatus.OK'))

Before collecting and processing the buildlog we will store the files
already created in /tmp so we can verify later that this mechanism is
not leaving any temporary file behind. See bug #172798.

    >>> import os
    >>> old_tmps = os.listdir('/tmp')

Collect and process the buildlog.

    >>> logfile_alias = buildergroup.getLogFromSlave(bqItem10)

Audit the /tmp for lost temporary files, there should not be any new
files. For the record, the procedure creates files with the
'.buildlog' suffix.

    >>> sorted(os.listdir('/tmp')) == sorted(old_tmps)
    True

The buildlog was compressed and directly transferred to Librarian.

    >>> from canonical.launchpad.interfaces import ILibraryFileAliasSet
    >>> logfile = getUtility(ILibraryFileAliasSet)[logfile_alias]
    >>> logfile.filename, logfile.mimetype
    (u'buildlog_ubuntu-warty-i386.foobar_1.0_FULLYBUILT.txt.gz', u'text/plain')

Needed so that the Librarian can serve the new file.

    >>> commit()

Check if the buildlog content is correct and accessible via the
library file directly and via Librarian http front-end.

Since LibrarianFileAlias does not implement required attributes for
gzip.open() (like tell() or seek()) we are obligated to read it again
in our filesystem.

    >>> import gzip, tempfile
    >>> fd, fname = tempfile.mkstemp()
    >>> tmp = open(fname, 'wb')
    >>> tmp.write(logfile.read())
    >>> tmp.close()
    >>> gzip.open(fname).read() == builder10.slave.getFile('buildlog').read()
    True

This also happens with urllib instance, we need to download it to the
filesystem before decompress.

    >>> import urllib
    >>> from_web = urllib.urlopen(logfile.http_url)
    >>> tmp = open(fname, 'wb')
    >>> tmp.write(from_web.read())
    >>> tmp.close()
    >>> gzip.open(fname).read() == builder10.slave.getFile('buildlog').read()
    True

Both access methods work as expected, remove the temporary file used here.

    >>> os.remove(fname)

Check the log from the uploader run has made it into the upload directory:

    >>> failed_dir = os.path.join(config.builddmaster.root, 'failed')
    >>> failed_uploads = sorted(os.listdir(failed_dir))
    >>> len(failed_uploads)
    2

    >>> failed_upload = failed_uploads[0]
    >>> uploader_log = open(os.path.join(failed_dir, failed_upload,
    ...                                  'uploader.log'))

    >>> print uploader_log.read()
    INFO    creating lockfile
    DEBUG   Initialising connection.
    DEBUG   Beginning processing
    DEBUG   Creating directory /var/tmp/builddmaster/accepted
    DEBUG   Creating directory /var/tmp/builddmaster/rejected
    DEBUG   Creating directory /var/tmp/builddmaster/failed
    ...
    DEBUG   Rolling back any remaining transactions.
    DEBUG   Removing lock file: /var/lock/process-upload-buildd.lock
    <BLANKLINE>

Remove build upload results root

    >>> shutil.rmtree(config.builddmaster.root)

== BuilddMaster class ==

    >>> bm = BuilddMaster(logging.getLogger(), local_transaction)

Retrieve a known DistroArchSeries

    >>> from canonical.launchpad.interfaces import IDistributionSet
    >>> hoary_i386 = getUtility(IDistributionSet)['ubuntu']['hoary']['i386']

Create a totally bogus CHROOT

    >>> from canonical.launchpad.database import LibraryFileAlias
    >>> from canonical.launchpad.database import PocketChroot
    >>> from canonical.launchpad.interfaces import PackagePublishingPocket
    >>> pocket = PackagePublishingPocket.RELEASE
    >>> chroot = LibraryFileAlias.get(1)
    >>> p = PocketChroot(distroarchseriesID=hoary_i386.id,
    ...                  pocket=pocket, chroot=chroot)

Setup a buildd-slave instance for a successful 'scan' procedure.

    >>> from canonical.buildd.ftests import BuilddSlaveTestSetup
    >>> BuilddSlaveTestSetup().setUp()

Initialise the BuildMaster with all available distroarchseries.
Because the sampledata builders are busy we issue and warning stating that.

    >>> from canonical.launchpad.interfaces import IDistroArchSeriesSet
    >>> for dar in sorted(getUtility(IDistroArchSeriesSet),
    ...                   key=lambda dar: (dar.distroseries.distribution.name,
    ...                                    dar.distroseries.name,
    ...                                    dar.architecturetag)):
    ...     bm.addDistroArchSeries(dar)
    ...     bm.setupBuilders(dar)

Scan active builders looking for information about current jobs,
collect result of finished jobs, everything is stored directly in
the Launchpad DB. (simply check if it doesn't explode)

    >>> bm.scanActiveBuilders()
    WARNING:root.builders.x86:Builder http://localhost:8221/ forgot about build i386 build of mozilla-firefox 0.9 in ubuntu warty RELEASE -- resetting buildqueue record

We are done here, let's stop the buildd-slave instance:

    >>> BuilddSlaveTestSetup().tearDown()

== Build Dispatching ==

Build dispatching can be entirely done via IBuilder content class via
the following API:

 * findCandidate:  returns a suitable BuildQueue candidate
 * dispatchBuildCandidate: dispatch a build for a given candidate.

IBuilder.findCandidate also identifies if there are builds for
superseded source package releases in the queue and marks the
corresponding build record as SUPERSEDED.

    >>> old_candidate = a_builder.findBuildCandidate()
    >>> print old_candidate.build.buildstate.name
    NEEDSBUILD

The 'candidate' is constant until we dispatch it.

    >>> new_candidate = a_builder.findBuildCandidate()
    >>> new_candidate.id == old_candidate.id
    True

In order to make the current candidate be considered 'superseded' we
need to tweak the status of the current publication directly, as a
permissive database user.

    >>> from canonical.config import config
    >>> from canonical.launchpad.interfaces import PackagePublishingStatus
    >>> from canonical.launchpad.database.publishing import (
    ...     SecureSourcePackagePublishingHistory)
    >>> from canonical.testing.layers import LaunchpadZopelessLayer

    >>> spr = old_candidate.build.sourcepackagerelease
    >>> current_pub = spr.publishings[0]
    >>> secure_pub = SecureSourcePackagePublishingHistory.get(current_pub.id)
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> secure_pub.status = PackagePublishingStatus.SUPERSEDED
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)

Now, there we have another build candidate.

    >>> new_candidate = a_builder.findBuildCandidate()
    >>> new_candidate.id != old_candidate.id
    True

Because the 'previous' candidate was marked as superseded, so it's not
part of the candidates list anymore.

    >>> print old_candidate.build.buildstate.name
    SUPERSEDED

For building a candidate in the release pocket for the main component
and the primary archive It will pass an 'archives' argument to the
slave that contains sources.list entries for each pocket required in
the primary archive dependency tree.

We also pass arguments called 'suite' which is the current distroseries and
pocket, (e.g. edgy-updates) and 'archive_purpose' which contains the build's
archive.purpose (e.g. PRIMARY or PPA).  These latter two arguments are
used in the chroot to determine whether it needs to turn on some features
or not (like pkgstriptranslations and pkgmaintainermangler).

    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> a_builder.is_available
    True
    >>> candidate = a_build.createBuildQueueEntry()
    >>> a_builder.dispatchBuildCandidate(candidate)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main
    Suite: hoary
    Archive Purpose: PRIMARY
    Archive Private: False

    >>> candidate.destroySelf()

Currently we can theoretically dispatch a build candidate for a
builder in 'manual' mode.

Although this will not be optimal, because we can only
do it once the manual builder has been collected (due to the
BuildQueue.builder constraint). Also because we don't yet provide a
API/UI method to request the dispatch in advance.

    >>> a_builder.manual = True
    >>> commit()
    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> a_builder.is_available
    True
    >>> candidate = a_build.createBuildQueueEntry()
    >>> a_builder.dispatchBuildCandidate(candidate)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main
    Suite: hoary
    Archive Purpose: PRIMARY
    Archive Private: False

    >>> candidate.destroySelf()

Partner archive builds will set up the 'archives' argument such that it
references all the required pockets/components in the primary archive, in
addition to a reference to the release pocket in the partner archive itself.

    >>> ubuntu = getUtility(IDistributionSet)['ubuntu']
    >>> partner_archive = ubuntu.getArchiveByComponent('partner')
    >>> removeSecurityProxy(a_build).archive = partner_archive
    >>> commit()
    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> a_builder.is_available
    True

    >>> candidate = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(candidate, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

    >>> a_builder.dispatchBuildCandidate(candidate)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-security main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-updates main restricted universe multiverse
     deb http://launchpad.dev/ubuntu-partner hoary main
    Suite: hoary
    Archive Purpose: PARTNER
    Archive Private: False

    >>> removeSecurityProxy(a_build).archive = ubuntu.main_archive
    >>> candidate.destroySelf()

Similarly, PPA builds pass the 'archives' arguments:

    >>> from canonical.launchpad.interfaces import IPersonSet
    >>> cprov_archive = getUtility(IPersonSet).getByName('cprov').archive
    >>> removeSecurityProxy(a_build).archive = cprov_archive
    >>> a_builder.virtualized = True
    >>> a_builder.vm_host = 'localhost.ppa'
    >>> commit()
    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> a_builder.is_available
    True

    >>> candidate = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(candidate, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

    >>> a_builder.dispatchBuildCandidate(candidate)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-security main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-updates main restricted universe multiverse
     deb http://ppa.launchpad.dev/cprov/ubuntu hoary main
    Suite: hoary
    Archive Purpose: PPA
    Archive Private: False

If the build is for a private PPA, the slave scanner will pass a
sources.list entry that contains a password to access the archive.

Make cprov's archive private and set the buildd_secret (which is the
password for the archive):

    >>> from canonical.testing import LaunchpadZopelessLayer
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> login('foo.bar@canonical.com')
    >>> cprov_archive.private = True
    >>> cprov_archive.buildd_secret = "secret"
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(test_dbuser)
    >>> login(ANONYMOUS)

Dispatch the build again.  Cprov's sources.list entry now has the
buildd:secret@ part in the URL.  Also note that because it's a private
PPA, it's missing the dependency on the updates pocket.  This is mainly
to accommodate the security build private PPA which must not depend
on the updates pocket.  This will be replaced in the future by a
proper solution that allows configurable pocket dependencies.

    >>> a_builder.dispatchBuildCandidate(candidate)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://buildd:secret@private.ppa.launchpad.dev/cprov/ubuntu hoary main
     deb http://ftpmaster.internal/ubuntu hoary main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-security main restricted universe multiverse
    Suite: hoary
    Archive Purpose: PPA
    Archive Private: True

    >>> candidate.destroySelf()

A PPA can depend on another PPA. We can make Celso's PPA depend on
Mark's PPA:


    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> login('foo.bar@canonical.com')

    >>> cprov_archive.private = False
    >>> sabdfl_archive = getUtility(IPersonSet).getByName('sabdfl').archive
    >>> unused_dep = cprov_archive.addArchiveDependency(sabdfl_archive)

    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(test_dbuser)
    >>> login(ANONYMOUS)

Now we can see that a build from Celso's PPA will be able to install
dependencies from Mark's PPA.

    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> a_builder.is_available
    True

    >>> candidate = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(candidate, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

    >>> a_builder.dispatchBuildCandidate(candidate)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-security main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-updates main restricted universe multiverse
     deb http://ppa.launchpad.dev/cprov/ubuntu hoary main
     deb http://ppa.launchpad.dev/sabdfl/ubuntu hoary main
    Suite: hoary
    Archive Purpose: PPA
    Archive Private: False

Clean up before continuing:

    >>> candidate.destroySelf()
    >>> a_builder.virtualized = False
    >>> removeSecurityProxy(a_build).archive = ubuntu.main_archive
    >>> commit()

Builddmaster stops before starting to build a denied build.
Since hoary is in development, we are not able to dispatch
builds for post-release pockets:

    >>> candidate = a_build.createBuildQueueEntry()
    >>> setupBuildQueue(candidate, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Make a build in the updates pocket:

    >>> hoary = hoary_i386.distroseries
    >>> hoary_evo = hoary.getSourcePackage(
    ...    'evolution').currentrelease.sourcepackagerelease
    >>> updates_build = hoary_evo.createBuild(
    ...     distroarchseries=hoary_i386,
    ...     pocket=PackagePublishingPocket.UPDATES,
    ...     processor=hoary_i386.default_processor,
    ...     archive=hoary_i386.main_archive)
    >>> updates_bqItem = updates_build.createBuildQueueEntry()

    >>> hoary_i386.distroseries.status.name
    'DEVELOPMENT'
    >>> a_builder.dispatchBuildCandidate(updates_bqItem)
    Traceback (most recent call last):
    ...
    AssertionError: i386 build of evolution 1.0 in ubuntu hoary UPDATES (31) can not be built for pocket UPDATES: invalid pocket due to the series status of hoary.

== Pocket dependencies ==

When passing the archives property to a slave, the required pockets
are dependent on the pocket that we are building in, such that:

    >>> def show_pocket_deps():
    ...     print "Pocket    |   Dependencies"
    ...     print "----------+---------------"
    ...     for (key, value) in a_builder.pocket_dependencies.items():
    ...         print "%7s |" % (key.name,),
    ...         for pocket in value:
    ...             print pocket.name,
    ...         print

    >>> show_pocket_deps()
    Pocket    |   Dependencies
    ----------+---------------
      RELEASE | RELEASE
    BACKPORTS | RELEASE SECURITY UPDATES BACKPORTS
     SECURITY | RELEASE SECURITY
      UPDATES | RELEASE SECURITY UPDATES
     PROPOSED | RELEASE SECURITY UPDATES PROPOSED


Change the distroseries status for testing. FROZEN allows building in
all pockets:

    >>> from canonical.launchpad.interfaces import DistroSeriesStatus
    >>> hoary_i386.distroseries.status = DistroSeriesStatus.FROZEN

Now we can start a build in other pockets, and see what archives are
passed to the slave.

A build in the updates pocket:

    >>> bqItem3 = a_build.createBuildQueueEntry()
    >>> removeSecurityProxy(bqItem3.build).pocket = (
    ...     PackagePublishingPocket.UPDATES)
    >>> setupBuildQueue(bqItem3, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)
    >>> a_builder.dispatchBuildCandidate(bqItem3)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main
     deb http://ftpmaster.internal/ubuntu hoary-security main
     deb http://ftpmaster.internal/ubuntu hoary-updates main
    Suite: hoary-updates
    Archive Purpose: PRIMARY
    Archive Private: False

A build in the proposed pocket:

    >>> bqItem3 = a_build.createBuildQueueEntry()
    >>> removeSecurityProxy(bqItem3.build).pocket = (
    ...     PackagePublishingPocket.PROPOSED)
    >>> setupBuildQueue(bqItem3, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)
    >>> a_builder.dispatchBuildCandidate(bqItem3)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main
     deb http://ftpmaster.internal/ubuntu hoary-proposed main
     deb http://ftpmaster.internal/ubuntu hoary-security main
     deb http://ftpmaster.internal/ubuntu hoary-updates main
    Suite: hoary-proposed
    Archive Purpose: PRIMARY
    Archive Private: False

A build in the backports pocket:

    >>> bqItem3 = a_build.createBuildQueueEntry()
    >>> removeSecurityProxy(bqItem3.build).pocket = (
    ...     PackagePublishingPocket.BACKPORTS)
    >>> setupBuildQueue(bqItem3, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)
    >>> a_builder.dispatchBuildCandidate(bqItem3)
    ensurepresent called
    ensurepresent called
    OkSlave BUILDING
    Archives:
     deb http://ftpmaster.internal/ubuntu hoary main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-backports main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-security main restricted universe multiverse
     deb http://ftpmaster.internal/ubuntu hoary-updates main restricted universe multiverse
    Suite: hoary-backports
    Archive Purpose: PRIMARY
    Archive Private: False

A build in the security pocket:

    >>> bqItem3 = a_build.createBuildQueueEntry()
    >>> removeSecurityProxy(bqItem3.build).buildstate = (
    ...     BuildStatus.NEEDSBUILD)
    >>> removeSecurityProxy(bqItem3.build).pocket = (
    ...     PackagePublishingPocket.SECURITY)
    >>> setupBuildQueue(bqItem3, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

The pocket-dependency infrastructure is ready to deal with SECURITY
pocket, however we explicitly skip security builds when dispatching
because Embargoed-Archives and Restricted-UI implementations are not
yet ready.

    >>> a_builder.dispatchBuildCandidate(bqItem3)
    Traceback (most recent call last):
    ...
    AssertionError: Soyuz is not yet capable of building SECURITY uploads.

Builds for security pocket are marked as FAILEDTOBUILD inside
findBuildCandidate method, see doc/buildd-dispatching.txt


== Builder Status Handler ==

IBuilder.slaveStatus should return a size homogeneous tuple despite of
the current slave state. This tuple should contain, in this order:

 * slave status string:  'BuilderStatus.IDLE'
 * job identifier string: '1-1'
 * job status string: 'BuildStatus.OK' or None
 * logtail (last 1K output of the ongoing build) as xmlrpclib.Binary or None
 * result file list: {'foo.deb', 'foo.changes'} or None
 * dependencies string: 'bar baz zaz' or None


    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> a_builder.slaveStatus()
    ('BuilderStatus.IDLE', '', None, None, None, None)

    >>> a_builder.setSlaveForTesting(BuildingSlave())
    >>> a_builder.slaveStatus()
    ('BuilderStatus.BUILDING', '1-1', None, <xmlrpclib.Binary ...>, None, None)

    >>> a_builder.setSlaveForTesting(WaitingSlave(state='BuildStatus.OK'))
    >>> a_builder.slaveStatus()
    ('BuilderStatus.WAITING', '1-1', 'BuildStatus.OK', None, {}, None)

    >>> a_builder.setSlaveForTesting(AbortingSlave())
    >>> a_builder.slaveStatus()
    ('BuilderStatus.ABORTING', '1-1', None, None, None, None)

    >>> a_builder.setSlaveForTesting(AbortedSlave())
    >>> a_builder.slaveStatus()
    ('BuilderStatus.ABORTED', '1-1', None, None, None, None)
