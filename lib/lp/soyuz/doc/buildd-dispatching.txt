= Buildd Dispatching =

    >>> import transaction
    >>> import logging
    >>> logger = logging.getLogger()
    >>> logger.setLevel(logging.DEBUG)

The buildd dispatching basically consists of finding a available
slave in IDLE state, pushing any required files to it, then requesting
that it starts the build procedure. These tasks are implemented by the
BuilderSet and Builder classes.

Setup the test builder:

    >>> from canonical.buildd.tests import BuilddSlaveTestSetup
    >>> BuilddSlaveTestSetup().setUp()

Setup a suitable chroot for Hoary i386:

    >>> from canonical.librarian.interfaces import ILibrarianClient
    >>> from StringIO import StringIO
    >>> librarian_client = getUtility(ILibrarianClient)

    >>> content = 'anything'
    >>> alias_id = librarian_client.addFile(
    ...    'foo.tar.gz', len(content), StringIO(content), 'text/plain')

    >>> from canonical.launchpad.interfaces import ILibraryFileAliasSet
    >>> from lp.registry.interfaces.distribution import IDistributionSet
    >>> from lp.registry.interfaces.pocket import PackagePublishingPocket

    >>> hoary = getUtility(IDistributionSet)['ubuntu']['hoary']
    >>> hoary_i386 = hoary['i386']

    >>> chroot = getUtility(ILibraryFileAliasSet)[alias_id]
    >>> pc = hoary_i386.addOrUpdateChroot(chroot=chroot)

Activate builders present in sampledata, we need to be logged in as a
member of launchpad-buildd-admin:

    >>> from canonical.launchpad.ftests import login
    >>> login('celso.providelo@canonical.com')

Set IBuilder.builderok of all present builders:

    >>> from lp.buildmaster.interfaces.builder import IBuilderSet
    >>> builder_set = getUtility(IBuilderSet)

    >>> builder_set.count()
    2

    >>> from canonical.launchpad.ftests import syncUpdate
    >>> for b in builder_set:
    ...     b.builderok = True
    ...     syncUpdate(b)

Clean up previous BuildQueue results from sampledata:

    >>> from lp.buildmaster.interfaces.buildqueue import IBuildQueueSet
    >>> lost_job = getUtility(IBuildQueueSet).get(1)
    >>> lost_job.builder.name
    u'bob'
    >>> lost_job.destroySelf()

If the specified buildd slave reset command (used inside resumeSlaveHost())
fails, the slave will still be marked as failed.

    >>> from canonical.config import config
    >>> reset_fail_config = '''
    ...     [builddmaster]
    ...     vm_resume_command: /bin/false'''
    >>> config.push('reset fail', reset_fail_config)
    >>> frog_builder = builder_set['frog']
    >>> frog_builder.handleTimeout(logger, 'The universe just collapsed')
    WARNING:root:Resetting builder: http://localhost:9221/ -- The universe just collapsed
    ...
    WARNING:root:Failed to reset builder: http://localhost:9221/ -- Resuming failed:
    ...
    WARNING:root:Disabling builder: http://localhost:9221/ -- The universe just collapsed
    ...
    <BLANKLINE>

Since we were unable to reset the 'frog' builder it was marked as 'failed'.

    >>> frog_builder.builderok
    False

Restore default value for resume command.

    >>> ignored_config = config.pop('reset fail')

The 'bob' builder is available for build jobs.

    >>> bob_builder = builder_set['bob']
    >>> bob_builder.name
    u'bob'
    >>> bob_builder.virtualized
    False
    >>> bob_builder.is_available
    True
    >>> bob_builder.builderok
    True


== Builder dispatching API ==

Now let's check the build candidates which will be considered for the
builder 'bob':

    >>> from zope.security.proxy import removeSecurityProxy
    >>> job = removeSecurityProxy(bob_builder)._findBuildCandidate()

The single BuildQueue found is a non-virtual pending build:

    >>> job.id
    2
    >>> from lp.soyuz.interfaces.binarypackagebuild import (
    ...     IBinaryPackageBuildSet)
    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(job)
    >>> build.status.name
    'NEEDSBUILD'
    >>> job.builder is None
    True
    >>> job.date_started is None
    True
    >>> build.is_virtualized
    False

The build start time is not set yet either.

    >>> print build.date_first_dispatched
    None

Update the SourcePackageReleaseFile corresponding to this job:

    >>> content = 'anything'
    >>> alias_id = librarian_client.addFile(
    ...    'foo.dsc', len(content), StringIO(content), 'application/dsc')

    >>> sprf = build.source_package_release.files[0]
    >>> naked_sprf = removeSecurityProxy(sprf)
    >>> naked_sprf.libraryfile = getUtility(ILibraryFileAliasSet)[alias_id]
    >>> flush_database_updates()

Check the dispatching method itself:

    >>> dispatched_job = bob_builder.findAndStartJob()
    >>> job == dispatched_job
    True
    >>> bob_builder.builderok = True

    >>> flush_database_updates()

Verify if the job (BuildQueue) was updated appropriately:

    >>> job.builder.id == bob_builder.id
    True

    >>> dispatched_build = getUtility(
    ...     IBinaryPackageBuildSet).getByQueueEntry(job)
    >>> dispatched_build == build
    True

    >>> build.status.name
    'BUILDING'

Shutdown builder, mark the build record as failed and remove the
buildqueue record, so the build was eliminated:

    >>> BuilddSlaveTestSetup().tearDown()

    >>> from lp.buildmaster.enums import BuildStatus
    >>> build.status = BuildStatus.FAILEDTOBUILD
    >>> job.destroySelf()
    >>> flush_database_updates()


== PPA build dispatching ==

Create a new Build record of the same source targeted for a PPA archive:

    >>> from lp.registry.interfaces.person import IPersonSet
    >>> cprov = getUtility(IPersonSet).getByName('cprov')

    >>> ppa_build = sprf.sourcepackagerelease.createBuild(
    ...     hoary_i386, PackagePublishingPocket.RELEASE, cprov.archive)

Create BuildQueue record and inspect some parameters:

    >>> ppa_job = ppa_build.queueBuild()
    >>> ppa_job.id
    3
    >>> ppa_job.builder == None
    True
    >>> ppa_job.date_started == None
    True

The build job's archive requires virtualized builds.

    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(ppa_job)
    >>> build.archive.require_virtualized
    True

But the builder is not virtualized.

    >>> bob_builder.virtualized
    False

Hence, the builder will not be able to pick up the PPA build job created
above.

    >>> bob_builder.vm_host = 'localhost.ppa'
    >>> syncUpdate(bob_builder)

    >>> job = removeSecurityProxy(bob_builder)._findBuildCandidate()
    >>> print job
    None

In order to enable 'bob' to find and build the PPA job, we have to
change it to virtualized.  This is because PPA builds will only build
on virtualized builders.  We also need to make sure this build's source
is published, or it will also be ignored (by superseding it).  We can
do this by copying the existing publication in Ubuntu.

    >>> from lp.soyuz.model.publishing import (
    ...     SourcePackagePublishingHistory)
    >>> [old_pub] = SourcePackagePublishingHistory.selectBy(
    ...    distroseries=build.distro_series,
    ...    sourcepackagerelease=build.source_package_release)
    >>> new_pub = old_pub.copyTo(
    ...     old_pub.distroseries, old_pub.pocket, build.archive)

    >>> bob_builder.virtualized = True
    >>> syncUpdate(bob_builder)

    >>> job = removeSecurityProxy(bob_builder)._findBuildCandidate()
    >>> ppa_job.id == job.id
    True

For further details regarding IBuilder._findBuildCandidate() please see
lib/lp/soyuz/tests/test_builder.py.

Start buildd-slave to be able to dispatch jobs.

    >>> BuilddSlaveTestSetup().setUp()

Before dispatching we can check if the builder is protected against
mistakes in code that results in a attempt to build a virtual job in
a non-virtual build.

    >>> bob_builder.virtualized = False
    >>> flush_database_updates()
    >>> removeSecurityProxy(bob_builder)._dispatchBuildCandidate(ppa_job)
    Traceback (most recent call last):
    ...
    AssertionError: Attempt to build non-virtual item on a virtual builder.

Mark the builder as virtual again, so we can dispatch the ppa job
successfully.

    >>> bob_builder.virtualized = True
    >>> flush_database_updates()

    >>> dispatched_job = bob_builder.findAndStartJob()
    >>> ppa_job == dispatched_job
    True

    >>> flush_database_updates()

PPA job is building.

    >>> ppa_job.builder.name
    u'bob'

    >>> build.status.name
    'BUILDING'

Shutdown builder slave, mark the ppa build record as failed, remove the
buildqueue record and make 'bob' builder non-virtual again,  so the
environment is back to the initial state.

    >>> BuilddSlaveTestSetup().tearDown()

    >>> build.status = BuildStatus.FAILEDTOBUILD
    >>> ppa_job.destroySelf()
    >>> bob_builder.virtualized = False
    >>> flush_database_updates()


== Security build dispatching ==

Setup chroot for warty/i386.

    >>> warty = getUtility(IDistributionSet)['ubuntu']['warty']
    >>> warty_i386 = warty['i386']
    >>> pc = warty_i386.addOrUpdateChroot(chroot=chroot)

Create a new Build record for test source targeted to warty/i386
architecture and SECURITY pocket:

    >>> sec_build = sprf.sourcepackagerelease.createBuild(
    ...     warty_i386, PackagePublishingPocket.SECURITY, hoary.main_archive)

Create BuildQueue record and inspect some parameters:

    >>> sec_job = sec_build.queueBuild()
    >>> sec_job.id
    4
    >>> print sec_job.builder
    None
    >>> print sec_job.date_started
    None
    >>> sec_build.is_virtualized
    False

In normal conditions the next available candidate would be the job
targeted to SECURITY pocket. However, the builders are forbidden to
accept such jobs until we have finished the EMBARGOED archive
implementation.

    >>> BuilddSlaveTestSetup().setUp()
    >>> removeSecurityProxy(bob_builder)._dispatchBuildCandidate(sec_job)
    Traceback (most recent call last):
    ...
    AssertionError: Soyuz is not yet capable of building SECURITY uploads.
    >>> BuilddSlaveTestSetup().tearDown()

To solve this problem temporarily until we start building security
uploads, we will mark builds targeted to the SECURITY pocket as
FAILEDTOBUILD during the _findBuildCandidate look-up.

We will also create another build candidate in breezy-autotest/i386 to
check if legitimate pending candidates will remain valid.

    >>> breezy = getUtility(IDistributionSet)['ubuntu']['breezy-autotest']
    >>> breezy_i386 = breezy['i386']
    >>> pc = breezy_i386.addOrUpdateChroot(chroot=chroot)

    >>> pending_build = sprf.sourcepackagerelease.createBuild(
    ...     breezy_i386, PackagePublishingPocket.UPDATES, hoary.main_archive)
    >>> pending_job = pending_build.queueBuild()

We set the score of the security job to ensure it is considered
before the legitimate job.

    >>> sec_job.lastscore = pending_job.lastscore + 1
    >>> flush_database_updates()

New we can check that the next valid candidate is the just-added
'pending_job', ensuring that it's published before doing so.

    >>> new_pub = old_pub.copyTo(
    ...     pending_build.distro_series, old_pub.pocket, pending_build.archive)
    >>> candidate = removeSecurityProxy(bob_builder)._findBuildCandidate()
    >>> flush_database_updates()
    >>> candidate.id == pending_job.id
    True

And as expected, the security job was marked as FAILEDTOBUILD and the
corresponding BuildQueue record was removed.  This way the security
builds, created due to missing binary uploads from DAK, will be
appropriately recorded and ignored.

    >>> print sec_build.status.name
    FAILEDTOBUILD
    >>> print sec_build.buildqueue_record
    None
