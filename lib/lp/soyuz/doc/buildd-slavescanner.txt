= Buildd Slave Scanner =

The Buildd Slave scanner is able to run over the build jobs being
processed in the current BuildFarm and collect information about the
status of the process, collect the results of finished jobs and
automatically dispatch new jobs to idle slaves.

The Master side of Buildd requires access to Launchpad Database, the
user designed for this kind of access is 'fiera', as in all test the
transaction should be retrieved.

    >>> from canonical.database.sqlbase import ZopelessTransactionManager
    >>> local_transaction = ZopelessTransactionManager._installed

We check for sent mails in some places, so load the stub mailer:

    >>> from lp.services.mail import stub
    >>> from canonical.database.sqlbase import commit

And create a utility function to make tests easier to read.

    >>> def check_mail_sent(last_stub_mail_count):
    ...    commit()
    ...    return len(stub.test_emails) == last_stub_mail_count + 3

The master also requires an 'logging' instance to not compromise the
standard output with noisily output.

    >>> import logging
    >>> logger = logging.getLogger()

Import MockBuilder and a series of MockSlaves to be used in this test.

    >>> from lp.buildmaster.tests.mock_slaves import (
    ...    AbortedSlave, AbortingSlave, BuildingSlave,
    ...    LostBuildingBrokenSlave, MockBuilder, OkSlave, WaitingSlave)

Slave-scanner will deactivate a 'lost-building' builder that could not
be aborted appropriately.

    >>> from zope.security.proxy import removeSecurityProxy
    >>> from lp.buildmaster.interfaces.builder import CorruptBuildCookie
    >>> from lp.testing.fakemethod import FakeMethod
    >>> lostbuilding_builder = MockBuilder(
    ...     'Lost Building Broken Slave', LostBuildingBrokenSlave())
    >>> behavior = removeSecurityProxy(
    ...     lostbuilding_builder.current_build_behavior)
    >>> behavior.verifySlaveBuildCookie = FakeMethod(
    ...     failure=CorruptBuildCookie("Hopelessly lost!"))

    >>> lostbuilding_builder.updateStatus(logger)
    Aborting slave
    WARNING:root:Lost Building Broken Slave (http://fake:0000) marked as failed due to: <Fault 8002: 'Could not abort'>
    Traceback (most recent call last):
    ...
    Fault: <Fault 8002: 'Could not abort'>

'ensurePresent()' slave method always return True, it theoretically
means the slave has the requested file in cache.  In our MockBuilder
we simply display the URL of the file we're asked to get from the
librarian.  Typically the first file is always the chroot, which in
the case of this doctest is a dummy alias pointing at netapplet (!) so
it is not shown in each case below.

The mock slaves will also print, when necessary, whether it has been
passed an 'archives' property in the args dictionary.

The archives are passed from the buildmaster and controls what archives
exist in the apt sources.list.  If nothing is passed, the chroot's default
list applies, otherwise the passed list is used.  This behavior is required
in build slaves because some jobs may only depend on certain archives and
hence certain package dependencies.

The slavescanner system also perform build-notification for the
following states: FAILEDTOBUILD and CHROOTWAIT

    >>> from lp.buildmaster.interfaces.builder import IBuilderSet
    >>> from lp.soyuz.interfaces.binarypackagebuild import (
    ...     IBinaryPackageBuildSet)
    >>> import datetime, pytz

    >>> UTC = pytz.timezone('UTC')

We want to get a Build and make BuildQueue items for it:

    >>> a_build = getUtility(IBinaryPackageBuildSet).getByBuildID(8)

To make testing easier we provide a convenience function to put a BuildQueue
object into a preset fixed state:

    >>> default_start = datetime.datetime(2005, 1, 1, 8, 0, 0, tzinfo=UTC)
    >>> def setupBuildQueue(build_queue, builder):
    ...     build_queue.markAsBuilding(builder)

Remove any previous buildmaster ROOT directory, to avoid any garbage
lock conflict (it would be recreated automatically if necessary)

    >>> from canonical.config import config
    >>> import shutil
    >>> import os
    >>> if os.access(config.builddmaster.root, os.F_OK):
    ...     shutil.rmtree(config.builddmaster.root)

Let's check the procedures to verify/collect running build process:

  WAITING - PACKAGEFAIL -> Package has failed to build, notice from
  builder is stored, but Build.status is mark as 'Failed to Build':

Get a builder from the sample data:

    >>> a_builder = getUtility(IBuilderSet).get(1)

Make sure that a_builder has no active builds:

    >>> if a_builder.currentjob is not None:
    ...     currentjob = a_builder.currentjob
    ...     currentjob.setDateStarted(None)
    ...     currentjob.builder = None

Force the test builder to be 'ok' as the code required to do this
automatically is not yet factored into the content class.

    >>> a_builder.builderok = True

Create a mock slave so the builder can operate - one with a failed package.

    >>> a_builder.setSlaveForTesting(WaitingSlave('BuildStatus.PACKAGEFAIL'))

    >>> bqItem3 = a_build.buildqueue_record
    >>> setupBuildQueue(bqItem3, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Do the test execution:

    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(bqItem3)
    >>> a_builder.updateBuild(bqItem3)
    >>> build.builder is not None
    True
    >>> build.date_finished is not None
    True
    >>> build.duration is not None
    True
    >>> build.log is not None
    True
    >>> check_mail_sent(last_stub_mail_count)
    True
    >>> build.status.title
    'Failed to build'

WAITING - DEPWAIT -> a required dependency is missing, again notice
from builder, but Build.status has the right state:

    >>> bqItem4 = a_build.queueBuild()
    >>> setupBuildQueue(bqItem4, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder can operate - one with a dependency error.

    >>> bqItem4.builder.setSlaveForTesting(
    ...                        WaitingSlave('BuildStatus.DEPFAIL',
    ...                                     'baz (>= 1.0.1)'))

Do the test execution:

    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(bqItem4)
    >>> a_builder.updateBuild(bqItem4)
    CRITICAL:slave-scanner:***** bob is MANUALDEPWAIT *****
    >>> build.builder is not None
    True
    >>> build.date_finished is not None
    True
    >>> build.duration is not None
    True
    >>> build.log is not None
    True
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> build.dependencies
    u'baz (>= 1.0.1)'
    >>> build.status.title
    'Dependency wait'

WAITING - CHROOTFAIL -> the Chroot for this distroseries is damage, nor
builder, but right state stored in Build entry:

    >>> bqItem5 = a_build.queueBuild()
    >>> setupBuildQueue(bqItem5, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

  Create a mock slave so the builder can operate - one with a failed chroot.

    >>> bqItem5.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.CHROOTFAIL'))
    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(bqItem5)
    >>> a_builder.updateBuild(bqItem5)
    CRITICAL:slave-scanner:***** bob is CHROOTWAIT *****
    >>> build.builder is not None
    True
    >>> build.date_finished is not None
    True
    >>> build.duration is not None
    True
    >>> build.log is not None
    True
    >>> check_mail_sent(last_stub_mail_count)
    True
    >>> build.status.title
    'Chroot problem'

WAITING - BUILDERFAIL -> builder has failed by internal error, job is available for next build round:

    >>> bqItem6 = a_build.queueBuild()
    >>> bqItem6.markAsBuilding(a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder can operate - one with a builder error.

    >>> bqItem6.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.BUILDERFAIL'))

    >>> a_builder.updateBuild(bqItem6)
    WARNING:slave-scanner:***** bob has failed *****

    >>> from canonical.launchpad.ftests import sync
    >>> sync(a_builder)
    >>> a_builder.failnotes
    u'Builder returned BUILDERFAIL when asked for its status'

    >>> bqItem6.builder is None
    True
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(bqItem6)
    >>> print build.status.title
    Needs building
    >>> job = bqItem6.specific_job.job
    >>> print job.status.title
    Waiting

Cleanup in preparation for the next test:

    >>> bqItem6.destroySelf()
    >>> a_builder.builderok = True


BUILDING -> builder still processing the job, simply collect the logtail:

    >>> bqItem7 = a_build.queueBuild()
    >>> setupBuildQueue(bqItem7, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder can operate - one which is building.

    >>> bqItem7.builder.setSlaveForTesting(BuildingSlave())
    >>> builder_id = bqItem7.builder.id
    >>> a_builder.updateBuild(bqItem7)

Due to updateBuild doing a commit we cannot compare the object instance.

    >>> bqItem7.builder.id is builder_id
    True
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> bqItem7.logtail
    u'This is a build log'

Cleanup in preparation for the next test:

    >>> bqItem7.destroySelf()

ABORTED -> builder was aborted, release builder and reset job for the
next build round:

    >>> bqItem8 = a_build.queueBuild()
    >>> setupBuildQueue(bqItem8, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

    >>> bqItem8.builder.setSlaveForTesting(BuildingSlave())
    >>> a_builder.updateBuild(bqItem8)
    >>> bqItem8.builder.setSlaveForTesting(AbortedSlave())
    >>> bqItem8.builder.name
    u'bob'
    >>> a_builder.updateBuild(bqItem8)
    >>> bqItem8.builder is None
    True
    >>> print bqItem8.specific_job.build.status.name
    NEEDSBUILD

Cleanup in preparation for the next test:

    >>> bqItem8.destroySelf()

ABORTING -> builder is trying to terminate its children process, the
only action master can perform is polling the slave status until it
gets ABORTED.

    >>> bqItem9 = a_build.queueBuild()
    >>> setupBuildQueue(bqItem9, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

    >>> bqItem9.builder.setSlaveForTesting(AbortingSlave())
    >>> bqItem9.builder.name
    u'bob'
    >>> a_builder.updateBuild(bqItem9)
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> bqItem9.logtail
    u'Waiting for slave process to be terminated'

Cleanup in preparation for the next test:

    >>> bqItem9.destroySelf()


== Builder WAITING in OK state ==

This situation happens when the builder has finished the job and is
waiting for the master to collect its results.

The build record in question will end up as UPLOADING.

=== Uploading (UPLOADING) ===

    >>> bqItem10 = a_build.queueBuild()
    >>> setupBuildQueue(bqItem10, a_builder)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem10.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.OK'))

The build will progress to the UPLOADING state if the status from
the builder was OK:

    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(bqItem10)
    >>> a_builder.updateBuild(bqItem10)
    >>> build.status.title
    'Uploading build'

=== Successfully collected and uploaded  (FULLYBUILT) ===

Build item 6 has binary packages available in the sample data, letting us test
this case cleanly. We need to set the pocket to updates for this test as its
uploading to warty.

    >>> bqItem10 = getUtility(IBinaryPackageBuildSet).getByBuildID(
    ...     6).queueBuild()
    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(bqItem10)

XXX: The pocket attribute is not intended to be changed in regular code, but
for this test we want to change it on the fly. An alternative would be to add
new sample data for a build that can be uploaded with binary packages attached
to it.

    >>> from lp.registry.interfaces.pocket import PackagePublishingPocket
    >>> removeSecurityProxy(
    ...     build).pocket = PackagePublishingPocket.UPDATES
    >>> setupBuildQueue(bqItem10, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem10.builder.setSlaveForTesting(WaitingSlave('BuildStatus.OK'))

We do not store any build log information when the binary upload
processing succeeded.

    >>> build.upload_log is None
    True

    >>> bqItem10.destroySelf()

WAITING -> GIVENBACK - slave requested build record to be rescheduled.

    >>> bqItem11 = a_build.queueBuild()
    >>> bqItem11.markAsBuilding(a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem11.builder.setSlaveForTesting(
    ...     WaitingSlave('BuildStatus.GIVENBACK'))
    >>> a_builder.updateBuild(bqItem11)
    WARNING:slave-scanner:***** i386 build of mozilla-firefox 0.9 in ubuntu hoary RELEASE is GIVENBACK by bob *****

Ensure GIVENBACK build preserves the history for future use. (we
can't be sure if logtail will contain any information, because it
depends on how long the build took to be processed and how often we
scanned it)

    >>> bqItem11.builder is None
    True
    >>> bqItem11.date_started is None
    True
    >>> bqItem11.lastscore
    2505
    >>> check_mail_sent(last_stub_mail_count)
    False
    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(bqItem11)
    >>> print build.status.title
    Needs building
    >>> job = bqItem11.specific_job.job
    >>> print job.status.title
    Waiting

Cleanup in preparation for the next test:

    >>> bqItem11.destroySelf()

The Builddmaster should crash when collecting builds which are denied in
the given distroseries/pocket. Anytime it happens we need to manually
investigate why this build end up built. (should never happen in real
cases, and even so should be refused when we try to upload it.)

    >>> bqItem12 = getUtility(IBinaryPackageBuildSet).getByBuildID(
    ...     2).queueBuild()
    >>> setupBuildQueue(bqItem12, a_builder)
    >>> last_stub_mail_count = len(stub.test_emails)

Create a mock slave so the builder gets the right responses for this test.

    >>> bqItem12.builder.setSlaveForTesting(WaitingSlave('BuildStatus.OK'))
    >>> a_builder.updateBuild(bqItem12)
    Traceback (most recent call last):
    ...
    AssertionError: i386 build of mozilla-firefox 0.9 in ubuntu warty RELEASE (2) can not be built for pocket RELEASE: illegal status

We need 'a_builder' released (from 'bqItem12') so it can be associated with
'bqItem10' below.

    >>> bqItem12.builder = None

The log is collected and compressed locally using gzip algorithm,
let's see how this method works:

    >>> bqItem10 = getUtility(IBinaryPackageBuildSet).getByBuildID(
    ...     6).queueBuild()
    >>> setupBuildQueue(bqItem10, a_builder)
    >>> build = bqItem10.specific_job.build
    >>> from lp.buildmaster.enums import BuildStatus
    >>> build.status = BuildStatus.FULLYBUILT
    >>> bqItem10.builder.setSlaveForTesting(WaitingSlave('BuildStatus.OK'))

Before collecting and processing the log we will store the files
already created in /tmp so we can verify later that this mechanism is
not leaving any temporary file behind. See bug #172798.

    >>> old_tmps = os.listdir('/tmp')

Collect and process the log.

    >>> logfile_alias = build.getLogFromSlave(build)

Audit the /tmp for lost temporary files, there should not be any new
files. For the record, the procedure creates files with the
'.buildlog' suffix.

    >>> sorted(os.listdir('/tmp')) == sorted(old_tmps)
    True

The log was compressed and directly transferred to Librarian.

    >>> from canonical.launchpad.interfaces.librarian import ILibraryFileAliasSet
    >>> logfile = getUtility(ILibraryFileAliasSet)[logfile_alias]

    >>> print logfile.filename
    buildlog_ubuntu-warty-i386.foobar_1.0_FULLYBUILT.txt.gz

    >>> print logfile.mimetype
    text/plain

Needed so that the Librarian can serve the new file.

    >>> commit()

Check if the log content is correct and accessible via the
library file directly and via Librarian http front-end.

Since LibrarianFileAlias does not implement required attributes for
gzip.open() (like tell() or seek()) we are obligated to read it again
in our filesystem.

    >>> built_builder = MockBuilder(
    ...     'Package Successfully Built',
    ...      WaitingSlave('BuildStatus.OK'))

    >>> import gzip, tempfile
    >>> fd, fname = tempfile.mkstemp()
    >>> tmp = os.fdopen(fd, 'wb')
    >>> tmp.write(logfile.read())
    >>> tmp.close()
    >>> gzip.open(fname).read() == built_builder.slave.getFile('buildlog').read()
    True

This also happens with urllib instance, we need to download it to the
filesystem before decompress.

    >>> import urllib
    >>> from_web = urllib.urlopen(logfile.http_url)
    >>> tmp = open(fname, 'wb')
    >>> tmp.write(from_web.read())
    >>> tmp.close()
    >>> gzip.open(fname).read() == built_builder.slave.getFile('buildlog').read()
    True

Both access methods work as expected, remove the temporary file used here.

    >>> os.remove(fname)

The Librarian serves log files with 'gzip' content-encoding and
'text/plain' content-type. This combination instructs the browser to
decompress the file and display it inline, which makes it easier for
users to view it.

    >>> from canonical.launchpad.webapp.url import urlparse
    >>> parsed_url = urlparse(logfile.http_url)
    >>> netloc, path = parsed_url[1:3]

    >>> import httplib
    >>> con = httplib.HTTPConnection(netloc)
    >>> con.request("HEAD", path)
    >>> resp = con.getresponse()
    >>> headers = dict(resp.getheaders())

    >>> print headers['content-encoding']
    gzip

    >>> print headers['content-type']
    text/plain

Remove build upload results root

    >>> shutil.rmtree(config.builddmaster.root)
    >>> bqItem10.destroySelf()
    >>> setupBuildQueue(bqItem12, a_builder)


== Setup chroots ==

Retrieve a known DistroArchSeries

    >>> from lp.registry.interfaces.distribution import IDistributionSet
    >>> hoary_i386 = getUtility(IDistributionSet)['ubuntu']['hoary']['i386']
    >>> warty_i386 = getUtility(IDistributionSet)['ubuntu']['warty']['i386']

Create a totally bogus CHROOT

    >>> from canonical.launchpad.database import LibraryFileAlias
    >>> fake_chroot = LibraryFileAlias.get(1)
    >>> unused = hoary_i386.addOrUpdateChroot(fake_chroot)
    >>> unused = warty_i386.addOrUpdateChroot(fake_chroot)


== Build Dispatching ==

Build dispatching can be entirely done via IBuilder content class
using the findAndStartJob method.

We will use SoyuzTestPublisher to simulate the required context in the
next tests. Let's initialise it.

    >>> from lp.soyuz.tests.test_publishing import (
    ...     SoyuzTestPublisher)
    >>> from canonical.testing.layers import LaunchpadZopelessLayer

    >>> test_publisher = SoyuzTestPublisher()

    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')

    >>> test_publisher.prepareBreezyAutotest()

    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)

Helper function to create binary publications in this test.

    >>> def create_binary_publication_for(archive, distroseries, status):
    ...     commit()
    ...     LaunchpadZopelessLayer.switchDbUser('launchpad')
    ...     login('foo.bar@canonical.com')
    ...     pub_binaries = test_publisher.getPubBinaries(
    ...         archive=archive, distroseries=distroseries,
    ...         status=status)
    ...     commit()
    ...     LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)
    ...     login(ANONYMOUS)

We will reset the sampledata building job before continue with the
tests.

    >>> current_job = a_builder.currentjob
    >>> resurrect_build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(
    ...     current_job)
    >>> resurrect_build.status = BuildStatus.NEEDSBUILD
    >>> current_job.builder = None
    >>> current_job.setDateStarted(None)
    >>> current_job.lastscore = 0

IBuilder.findCandidate also identifies if there are builds for
superseded source package releases in the queue and marks the
corresponding build record as SUPERSEDED.

    >>> old_candidate = removeSecurityProxy(a_builder)._findBuildCandidate()
    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(
    ...     old_candidate)
    >>> print build.status.name
    NEEDSBUILD

The 'candidate' is constant until we dispatch it.

    >>> new_candidate = removeSecurityProxy(a_builder)._findBuildCandidate()
    >>> new_candidate.id == old_candidate.id
    True

Now let's disable the archive of the associated build record and see
whether the candidate will still be found.

    >>> build.archive.disable()
    >>> new_candidate = removeSecurityProxy(a_builder)._findBuildCandidate()
    >>> new_candidate is None
    True

The build candidate was not found because builds associated with disabled
archives are ignored. Now let's re-enable that archive and the build
candidate will be found again.

    >>> build.archive.enable()
    >>> new_candidate = removeSecurityProxy(a_builder)._findBuildCandidate()
    >>> new_candidate.id == old_candidate.id
    True

In order to make the current candidate be considered 'superseded' we
need to tweak the status of the current publication directly, as a
permissive database user.

    >>> from canonical.config import config
    >>> from lp.soyuz.enums import PackagePublishingStatus
    >>> from canonical.testing.layers import LaunchpadZopelessLayer

    >>> spr = build.source_package_release
    >>> pub = removeSecurityProxy(build).current_source_publication
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> pub.status = PackagePublishingStatus.SUPERSEDED
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)

Now, there we have another build candidate.

    >>> new_candidate = removeSecurityProxy(a_builder)._findBuildCandidate()
    >>> new_candidate.id != old_candidate.id
    True

Because the 'previous' candidate was marked as superseded, so it's not
part of the candidates list anymore.

    >>> print build.status.name
    SUPERSEDED

If the candidate is for a private build whose source has not been
published yet, it will be temporarily skipped until the source is
published.  We need to tweak the status of the publishing record again
to demonstrate this, and also make the archive private:

XXX Michael Nelson 2010-02-19 bug=394276 Please let's put some time
aside to convert these to unit-tests.

    >>> naked_build = removeSecurityProxy(
    ...     getUtility(IBinaryPackageBuildSet).getByQueueEntry(new_candidate))
    >>> original_archive = naked_build.archive
    >>> secure_pub = naked_build.current_source_publication
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> private_ppa = factory.makeArchive(private=True)
    >>> naked_build.archive = private_ppa
    >>> secure_pub.archive = private_ppa
    >>> secure_pub.status = PackagePublishingStatus.PENDING
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)

Let's try to find a new build candidate:

    >>> another_candidate = removeSecurityProxy(
    ...     a_builder)._findBuildCandidate()

Since there are no more candidates at all, _findBuildCandidate()
returned None:

    >>> print another_candidate
    None

If we publish the source, the build candidate will be found again:

    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> secure_pub.status = PackagePublishingStatus.PUBLISHED
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)

    >>> another_candidate = removeSecurityProxy(
    ...     a_builder)._findBuildCandidate()
    >>> another_candidate.id == new_candidate.id
    True

If the source is subsequently deleted or superseded before the build
starts it is also returned as a candidate so that the build can be
superseded.  We can supersede this publication which will have the effect of
making the build be superseded and no candidate is returned.

    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> secure_pub = naked_build.current_source_publication
    >>> secure_pub.status = PackagePublishingStatus.DELETED
    >>> secure_pub.status = PackagePublishingStatus.SUPERSEDED
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)

    >>> build = getUtility(IBinaryPackageBuildSet).getByQueueEntry(
    ...     current_job)
    >>> print build.status.name
    NEEDSBUILD

    >>> another_candidate = removeSecurityProxy(
    ...     a_builder)._findBuildCandidate()
    >>> print another_candidate
    None

    >>> print build.status.name
    SUPERSEDED

We'll reset the archive back to non-private for further tests:

    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> naked_build.archive = original_archive
    >>> secure_pub.archive = original_archive
    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser(config.builddmaster.dbuser)

Partner archive builds will set up the 'archives' argument such that it
references all the required pockets/components in the primary archive, in
addition to a reference to the release pocket in the partner archive itself.

    >>> ubuntu = getUtility(IDistributionSet)['ubuntu']
    >>> partner_archive = ubuntu.getArchiveByComponent('partner')
    >>> removeSecurityProxy(a_build).archive = partner_archive
    >>> commit()
    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> a_builder.is_available
    True

The partner archive won't be passed to the builder unless it has at
least one published binary availble in the target distroarchseries.
This feature fixes bug #196782, when archive/suites got passed to
builders before they get published on disk, i.e. the first build on
any PPA/suite will fail during the first 20 minutes because no empty
indexes are published.

Since this is a build in a private archive, the log was uploaded to
the restricted librarian.

    >>> removeSecurityProxy(build).archive = private_ppa
    >>> commit()
    >>> candidate = build.queueBuild()
    >>> setupBuildQueue(candidate, a_builder)
    >>> build.upload_log = None
    >>> candidate.builder.setSlaveForTesting(WaitingSlave('BuildStatus.OK'))
    >>> a_builder.updateBuild(candidate)
    >>> local_transaction.commit()

    >>> build.archive.private
    True

    >>> lfa = build.log
    >>> lfa.restricted
    True
    >>> print lfa.filename
    buildlog_ubuntu-warty-i386.mozilla-firefox_0.9_BUILDING.txt.gz

The attempt to fetch the buildlog from the common librarian will fail
since this is a build in a private archive and the buildlog was thus
uploaded to the restricted librarian.

    >>> from canonical.librarian.interfaces import ILibrarianClient
    >>> getUtility(ILibrarianClient).getFileByAlias(lfa.id)
    Traceback (most recent call last):
      ...
    DownloadFailed: Alias ... cannot be downloaded from this client.

Accessing the log via the restricted librarian will work as expected.

    >>> import urlparse
    >>> from canonical.librarian.interfaces import IRestrictedLibrarianClient
    >>> lfa2 = removeSecurityProxy(
    ...     getUtility(IRestrictedLibrarianClient).getFileByAlias(lfa.id))
    >>> url_parts = urlparse.urlsplit(lfa2.file.geturl())
    >>> print os.path.basename(url_parts[2])
    buildlog_ubuntu-warty-i386.mozilla-firefox_0.9_BUILDING.txt.gz

A PPA can depend on another PPA. We can make Celso's PPA depend on
Mark's PPA:

    >>> commit()
    >>> LaunchpadZopelessLayer.switchDbUser('launchpad')
    >>> login('foo.bar@canonical.com')


Clean up before continuing:

    >>> a_builder.virtualized = False
    >>> removeSecurityProxy(a_build).archive = ubuntu.main_archive
    >>> commit()


== Builder Status Handler ==

IBuilder.slaveStatus should return a dict containing the following
items:

 * slave status string:  'BuilderStatus.IDLE'
 * job identifier string: '1-1'
 * job status string: 'BuildStatus.OK' or None
 * logtail (last 1K output of the ongoing build) as xmlrpclib.Binary or None
 * result file list: {'foo.deb', 'foo.changes'} or None
 * dependencies string: 'bar baz zaz' or None

    # Define a helper to print the slave status dict.
    >>> from collections import defaultdict
    >>> def printSlaveStatus(status_dict):
    ...     status_dict = defaultdict(lambda:None, status_dict)
    ...     print (
    ...         "builder_status: %(builder_status)s\n"
    ...         "build_status: %(build_status)s\n"
    ...         "logtail: %(logtail)r\n"
    ...         "filemap: %(filemap)s\n"
    ...         "dependencies: %(dependencies)s\n" % status_dict)

    >>> a_builder.setSlaveForTesting(OkSlave())
    >>> printSlaveStatus(a_builder.slaveStatus())
    builder_status: BuilderStatus.IDLE
    build_status: None
    logtail: None
    filemap: None
    dependencies: None

    >>> a_builder.setSlaveForTesting(BuildingSlave())
    >>> printSlaveStatus(a_builder.slaveStatus())
    builder_status: BuilderStatus.BUILDING
    build_status: None
    logtail: <xmlrpclib.Binary ...>
    filemap: None
    dependencies: None

    >>> a_builder.setSlaveForTesting(WaitingSlave(state='BuildStatus.OK'))
    >>> printSlaveStatus(a_builder.slaveStatus())
    builder_status: BuilderStatus.WAITING
    build_status: BuildStatus.OK
    logtail: None
    filemap: {}
    dependencies: None

    >>> a_builder.setSlaveForTesting(AbortingSlave())
    >>> printSlaveStatus(a_builder.slaveStatus())
    builder_status: BuilderStatus.ABORTING
    build_status: None
    logtail: None
    filemap: None
    dependencies: None

    >>> a_builder.setSlaveForTesting(AbortedSlave())
    >>> printSlaveStatus(a_builder.slaveStatus())
    builder_status: BuilderStatus.ABORTED
    build_status: None
    logtail: None
    filemap: None
    dependencies: None

