Soyuz Set of Uploads Test
-------------------------

This test is prefixed with 'zzz-' in order to ensure it is run last
because it inserts a large amount of stuff into the database and will
leave things in a state likely to confuse the rest of the test set if
it were run mid-sequence.

This test will:

  * Turn on the zeca keyserver
  * Run process-upload.py
  * Check result
  * Mark packages as ACCEPTED
  * Runs process-accepted.py
  * Check results
  * Cleanup


Uploading Packages
------------------


We need the librarian for this test.

  >>> from canonical.librarian.ftests.harness import LibrarianTestSetup
  >>> LibrarianTestSetup().setUp()


First, let's create a temporary directory where we'll put
uploaded files in.

  >>> import os
  >>> import tempfile
  >>> temp_dir = tempfile.mkdtemp()
  >>> uploader_log = tempfile.mktemp()
  >>> incoming_dir = os.path.join(temp_dir, "incoming")
  >>> accepted_dir = os.path.join(temp_dir, "accepted")
  >>> rejected_dir = os.path.join(temp_dir, "rejected")
  >>> failed_dir = os.path.join(temp_dir, "failed")
  >>> os.mkdir(incoming_dir)


Processing Uploads
------------------

Before asking the system to process the upload, we must prepare the
database and services to receive it. Since we're using
'daniel.silverstone@canonical.com' as our Changed-By address and his
key has signed all the relevant uploads in the suite of uploads we're
using, this essentially boils down to ensuring that zeca and the
librarian are running and making sure that the key is attached to the
relevant launchpad person.

  >>> from canonical.librarian.ftests.harness import LibrarianTestSetup
  >>> LibrarianTestSetup().setUp()
  >>> from canonical.zeca.ftests.harness import ZecaTestSetup
  >>> ZecaTestSetup().setUp()
  >>> from canonical.launchpad.database import GPGKey, Person
  >>> from canonical.lp.dbschema import GPGKeyAlgorithm
  >>> dsa = GPGKeyAlgorithm.D
  >>> g = GPGKey(owner=Person.byName('kinnison'), keyid='20687895',
  ...            fingerprint='961F4EB829D7D304A77477822BC8401620687895',
  ...            keysize=1024, algorithm=dsa, active=True, can_encrypt=True)

  >>> g = GPGKey(owner=Person.byName('cprov'), keyid='681B6469',
  ...            fingerprint='C85826521A6EF6A6037BB3F79FF2583E681B6469',
  ...            keysize=1024, algorithm=dsa, active=True, can_encrypt=True)


Force weird behavior with rfc2047 sentences containing '.' on
bar_1.0-4, which caused bug # 41102.

  >>> p = Person.byName('cprov')
  >>> p.displayname = "Celso R. Providelo"

Having set up that infrastructure we need to prepare a breezy distrorelease
for the ubuntutest distribution.

  >>> from canonical.launchpad.database import Distribution
  >>> ut = Distribution.byName('ubuntutest')
  >>> ubuntu = Distribution.byName('ubuntu')
  >>> bat = ubuntu['breezy-autotest']
  >>> from canonical.launchpad.database import DistroReleaseSet
  >>> drs = DistroReleaseSet()
  >>> breezy = drs.new(ut, 'breezy', 'Breezy Badger', 'The Breezy Badger',
  ...                  'Black and White', 'Someone', '5.10', bat, bat.owner)
  >>> breezy_i386 = breezy.newArch('i386', bat['i386'].processorfamily,
  ...                              True, breezy.owner)
  >>> breezy.nominatedarchindep = breezy_i386
  >>> breezy.initialiseFromParent()

Commit all that so that the scripts can see it.

  >>> import transaction
  >>> transaction.commit()

Now that the infrastructure is ready, we prepare a set of useful methods.

Firstly, we need a way to copy a test upload into the queue

  >>> from canonical.archivepublisher.tests import datadir
  >>> def punt_upload_into_queue(leaf):
  ...     inc_dir = os.path.join(incoming_dir, leaf)
  ...     os.mkdir(inc_dir)
  ...     f = open(inc_dir + ".distro", "w")
  ...     f.write("ubuntutest")
  ...     f.close()
  ...     for file_leaf in os.listdir(datadir(os.path.join("suite", leaf))):
  ...         os.system("cp %s %s" %
  ...             (datadir(os.path.join("suite", leaf, file_leaf)), inc_dir))

We need a way to count the items in a queue directory

  >>> def count_items(queue):
  ...     return len(queue)

And then we need a way to process the uploads from the queue

  >>> from canonical.config import config
  >>> import subprocess, sys
  >>> def process_uploads(upload_policy):
  ...     # reset previous log content if it exists
  ...     if os.path.exists(uploader_log):
  ...         open(uploader_log, 'w').write('')
  ...     script = os.path.join(config.root, "scripts", "process-upload.py")
  ...     process = subprocess.Popen([sys.executable, script, "--no-mails",
  ...                                 "-v", "-C", upload_policy, temp_dir,
  ...                                 "--log-file", uploader_log])
  ...     return process.wait() == 0

And we need a way to process the accepted queue

  >>> def process_accepted():
  ...     script = os.path.join(config.root, "scripts", "process-accepted.py")
  ...     process = subprocess.Popen([sys.executable, script,
  ...                                "ubuntutest"],
  ...                                stdout=subprocess.PIPE,
  ...                                stderr=subprocess.PIPE)
  ...     # collects spurious output (as reported in bug # 39281)
  ...     garbage = process.stderr.read()
  ...     garbage = process.stdout.read()
  ...     return process.wait() == 0

If an upload of ours ends up in the NEW queue, we need a way to process
it into the accepted queue

  >>> def process_new():
  ...     script = os.path.join(config.root, "scripts",
  ...                           "ftpmaster-tools", "queue")
  ...     process = subprocess.Popen([sys.executable, script, "-Q", "new",
  ...                                 "-D", "ubuntutest", "-R", "breezy",
  ...                                 "--no-mail", "accept", "*"],
  ...                                stdout=subprocess.PIPE,
  ...                                stderr=subprocess.PIPE)
  ...     # collects spurious output (as reported in bug # 39281)
  ...     garbage = process.stderr.read()
  ...     garbage = process.stdout.read()
  ...     return process.wait() == 0

Finally, as a very simplistic publishing process, we may need to punt any
given upload into the published state, so here's a very simplistic publisher

  >>> from canonical.launchpad.database import (
  ...     SourcePackagePublishing as SPP, BinaryPackagePublishing as BPP)
  >>> from canonical.lp.dbschema import PackagePublishingStatus as PPS
  >>> from canonical.database.constants import nowUTC
  >>> def simple_publish():
  ...     transaction.abort()
  ...     srcs_to_publish = SPP.select("""
  ...         SourcePackagePublishing.distrorelease = DistroRelease.id
  ...     AND DistroRelease.distribution = Distribution.id
  ...     AND Distribution.name = 'ubuntutest'
  ...     AND SourcePackagePublishing.status = 1""",
  ...         clauseTables=['DistroRelease', 'Distribution'])
  ...     bins_to_publish = BPP.select("""
  ...         BinaryPackagePublishing.distroarchrelease = DistroArchRelease.id
  ...     AND DistroArchRelease.distrorelease = DistroRelease.id
  ...     AND DistroRelease.distribution = Distribution.id
  ...     AND Distribution.name = 'ubuntutest'
  ...     AND BinaryPackagePublishing.status = 1""",
  ...         clauseTables=['DistroArchRelease', 'DistroRelease',
  ...                       'Distribution'])
  ...     published_one = False
  ...     for src in srcs_to_publish:
  ...         src.status = PPS.PUBLISHED
  ...         src.datepublished = nowUTC
  ...         published_one = True
  ...     for bin in bins_to_publish:
  ...         bin.status = PPS.PUBLISHED
  ...         bin.datepublished = nowUTC
  ...         published_one = True
  ...     transaction.commit()
  ...     return published_one

Now that we have all the structures we need in the form of the
functions punt_upload_into_queue, process_uploads, process_accepted,
process_new and simple_publish we are in a position to run the tests.

We can also define another helper function...

  >>> def expect_okays(leafname, is_new, upload_policy='anything'):
  ...     punt_upload_into_queue(leafname)
  ...     assert process_uploads(upload_policy), "Upload processes failed"
  ...     # There is always a lockfile in incoming...
  ...     assert len(os.listdir(incoming_dir)) == 1, "Incoming should be empty"
  ...     assert len(os.listdir(rejected_dir)) == 0, "Rejected should be empty"
  ...     assert len(os.listdir(failed_dir)) == 0, "Failed should be empty"
  ...     if is_new:
  ...         assert(process_new())
  ...     assert(process_accepted())
  ...     assert simple_publish(), "Should publish at least one item"

The 'bar' package' is an arch-all package. We have four stages to the
bar test. Each stage should be simple enough. First we have a new
source, then a new binary, then an overridable source and then an
overridable binary. This tests the simple overriding of both sources
and arch-independant binaries.

  >>> expect_okays('bar_1.0-1', True)

  >>> expect_okays('bar_1.0-1_binary', True)

  >>> expect_okays('bar_1.0-2', False)

  >>> expect_okays('bar_1.0-2_binary', False)

Check the rejection of a malicious version of bar package which refers
to a different 'bar_1.0.orig.tar.gz'.

  >>> expect_okays('bar_1.0-3', False)
  Traceback (most recent call last):
  ...
  AssertionError: Rejected should be empty

Inspect the uploader log to find the rejection message.

  >>> print open(uploader_log).read()
  DEBUG   Initialising connection.
  ...
  INFO       Subject: bar_1.0-3_source.changes Rejected
  INFO       Recipients: Daniel Silverstone <daniel.silverstone@canonical.com>
  INFO       Body:
  INFO    Rejected:
  INFO    SHA1 sum of uploaded file does not match extant file in archive
  ...
  <BLANKLINE>

Remove rejected uploads.

  >>> import shutil
  >>> shutil.rmtree(os.path.join(rejected_dir, 'bar_1.0-3'))
  >>> os.remove(os.path.join(rejected_dir, 'bar_1.0-3.distro'))

Check the email recipient for displayname containing special chars,
'.', must be rfc2047 compilant:

  >>> expect_okays('bar_1.0-4', False)
  >>> print open(uploader_log).read()
  DEBUG   Initialising connection.
  ...
  INFO       Subject: Accepted bar 1.0-4 (source)
  INFO       Recipients: "Celso R. Providelo" <celso.providelo@canonical.com>
  ...
  <BLANKLINE>


Check if we forcibly add the changer as recipient for "sync" uploads,
which contains unsigned changesfile.

  >>> expect_okays('bar_1.0-5', False, upload_policy='sync')
  >>> print open(uploader_log).read()
  DEBUG   Initialising connection.
  ...
  DEBUG   Building recipients list.
  DEBUG   Changes file is unsigned, adding changer as recipient
  DEBUG   Adding recipient: '"Celso R. Providelo" <celso.providelo@canonical.com>'
  DEBUG   Creating a New queue entry
  DEBUG   Setting it to ACCEPTED
  INFO    Would be sending a mail:
  INFO       Subject: Accepted bar 1.0-5 (source)
  INFO       Recipients: "Celso R. Providelo" <celso.providelo@canonical.com>
  ...
  <BLANKLINE>


Nice! That's enough for now.. let's kill the process and clean
everything up.

  >>> shutil.rmtree(temp_dir)
  >>> os.remove(uploader_log)

  >>> ZecaTestSetup().tearDown()
  >>> LibrarianTestSetup().tearDown()
