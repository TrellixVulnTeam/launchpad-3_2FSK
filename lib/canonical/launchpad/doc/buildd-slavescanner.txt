Buildd Slave Scanner
====================

The Buildd Slave scanner is able to run over the build jobs being
processed in the current BuildFarm and collect information about the
status of the process, collect the results of finished jobs and
automaticaly dispatch new jobs to idle slaves.

  >>> from canonical.buildmaster.master import BuilddMaster

The Master side of Buildd requires access to Launchpad Database, the
user designed for this kind of access is 'fiera', as in all test the
transaction should be retrieved.

  >>> from canonical.database.sqlbase import ZopelessTransactionManager
  >>> local_transaction = ZopelessTransactionManager._installed

The master also requires an 'logging' instance to not compromise the
standard output with noisely output.

  >>> import logging

We use StringIO later to simulate bits of the build slave file retrieval

  >>> from StringIO import StringIO

First let's test a essencial part of the BuilddMaster class, the
BuildersGroup() class, by creating an empty BuilderGroup object

  >>> from canonical.buildmaster.buildergroup import BuilderGroup

  >>> buildergroup = BuilderGroup(
  ...     logging.getLogger(), local_transaction)

Mock Builder, a class to emulate the Builder behaviour:

  >>> class MockBuilder:
  ...     def __init__(self, name, slave):
  ...         self.slave = slave
  ...         self.builderok = True
  ...         self.manual = False
  ...         self.url = 'http://fake:0000'
  ...         slave.urlbase = self.url
  ...         self.name = name
  ...         self.trusted = False
  ...     def failbuilder(self, reason):
  ...         self.builderok = False
  ...         self.failnotes = reason
  ...     def slaveStatusSentence(self):
  ...         return self.slave.status()
  ...     def cleanSlave(self):
  ...         return self.slave.clean()
  ...     def requestAbort(self):
  ...         return self.slave.abort()
  ...     def resetSlaveHost(self, logger):
  ...         pass

Let's play with a BuilderGroup method designed to rescue build slaves
that are processing unknown jobs. In real conditions, this situation
only happens if the slave is processing deleted or modified BuildQueue
entry, since Build entries are never removed. It might be caused by
exceptions in slavescanner or queuebuilder scripts.

When we figured this situation out, the procedure to rescue is to
request the slave XMLRPC method 'clean', reseting the slave completely.

We figured out if the building information is correct and sane by
checking the job identifier field from status message information,
which consists of "<Build.id>-<BuildQueue.id>".

First let's emulate a sane and a lost slave. The SaneSlave returns a
job identifier that exists in our sampledata, but the LostSlave
returns a completly bogus one.

The the mock slave.clean() method is modified to print a message for
testing purposes.

Initializing the sane_builder. It was not rescued, since the job
identifier is sane (Build.id == 8 and BuildQueue.id == 1 exist):

  >>> class SaneBuildingSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.BUILDING', '8-1')
  ...     def clean(self):
  ...         print 'Rescuing SaneSlave'

  >>> sanebuilding_builder = MockBuilder('Sane Building Slave',
  ...                                    SaneBuildingSlave())

  >>> buildergroup.rescueBuilderIfLost(sanebuilding_builder) is None
  True

A sane WAITING slave:

  >>> class SaneWaitingSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.WAITING', 'BuildStatus.OK', '8-1')
  ...     def clean(self):
  ...         print 'Rescuing SaneSlave'

  >>> sanewaiting_builder = MockBuilder('Sane Waiting Slave',
  ...                                   SaneWaitingSlave())

  >>> buildergroup.rescueBuilderIfLost(sanewaiting_builder) is None
  True

A sane WAITING slave but with wrong BuildQueue/Build relation:

  >>> class SaneWaitingSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.WAITING', 'BuildStatus.OK', '7-1')
  ...     def clean(self):
  ...         pass

  >>> sanewaiting_builder = MockBuilder('Sane Waiting Slave',
  ...                                   SaneWaitingSlave())

  >>> buildergroup.rescueBuilderIfLost(sanewaiting_builder)
  WARNING:root:Builder 'Sane Waiting Slave' rescued from '7-1: Job build entry mismatch'

It was rescued because the BuildQueue.id == 1 isn't related to
Build.id == 7, so this pair relation is wrong.

Let's test slaves with job identifier pointing non-existent
Build/BuildQueue entries. first a lost slave in status 'BUILDING':

  >>> class LostBuildingSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.BUILDING', '1000-10000')
  ...     def abort(self):
  ...         pass

  >>> lostbuilding_builder = MockBuilder('Lost Building Slave',
  ...                                    LostBuildingSlave())

  >>> buildergroup.rescueBuilderIfLost(lostbuilding_builder)
  WARNING:root:Builder 'Lost Building Slave' rescued from '1000-10000: The object Build by the ID 1000 does not exist'

Then a lost slave in status 'WAITING':

  >>> class LostWaitingSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.WAITING', 'BuildStatus.OK', '1000-10000')
  ...     def clean(self):
  ...         pass

  >>> lostwaiting_builder = MockBuilder('Lost Waiting Slave',
  ...                                    LostWaitingSlave())

  >>> buildergroup.rescueBuilderIfLost(lostwaiting_builder)
  WARNING:root:Builder 'Lost Waiting Slave' rescued from '1000-10000: The object Build by the ID 1000 does not exist'

Both got rescued, as expected.


Let's create a bunch of mock slaves for testing the Builder State Handler:

  >>> import xmlrpclib
  >>> class BrokenSlave:
  ...     def status(self):
  ...         raise xmlrpclib.Fault(8001, "Broken slave")


Make ensurePresent() always return True, it teoretically means the
slave has the requested file in cache.

  >>> class OkSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.IDLE',)
  ...     def ensurepresent(self, sha1, url):
  ...         print "ensurepresent called"
  ...         return True, None
  ...     def build(self, buildid, buildtype, chroot, filemap, args):
  ...         info = 'OkSlave BUILDING'
  ...         print info
  ...         return ('BuildStatus.Building', info)

  >>> class BuildingSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.BUILDING', '1-1', "This is a build log")
  ...     def getFile(self, sum):
  ...         if sum == "buildlog":
  ...             s = StringIO("This is a build log")
  ...             s.headers={'content-length':19}
  ...             return s

  >>> class AbortedSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.ABORTED', '1-1')
  ...     def fetchlogtail(self, size):
  ...         return 'BOGUS'
  ...     def clean(self):
  ...         pass

  >>> class WaitingSlave:
  ...     def __init__(self, state, dependencies=None):
  ...         self.state = state
  ...         self.dependencies = dependencies
  ...     def status(self):
  ...         return ('BuilderStatus.WAITING', self.state, '1-1', {},
  ...                 self.dependencies )
  ...     def fetchlogtail(self, amount=None):
  ...         return 'BOGUS'
  ...     def clean(self):
  ...         pass
  ...     def getFile(self, sum):
  ...         if sum == "buildlog":
  ...             s = StringIO("This is a build log")
  ...             s.headers={'content-length':19}
  ...             return s

  >>> class AbortingSlave:
  ...     def status(self):
  ...         return ('BuilderStatus.ABORTING', '1-1')


  >>> builder1 = MockBuilder('Broken Slave', BrokenSlave())

  >>> builder2 = MockBuilder('Idle Slave', OkSlave())

  >>> builder3 = MockBuilder('Package Failed',
  ...                        WaitingSlave('BuildStatus.PACKAGEFAIL'))

  >>> builder4 = MockBuilder('Missing Dependency build',
  ...                        WaitingSlave('BuildStatus.DEPFAIL',
  ...                                     'baz (>= 1.0.1)'))

  >>> builder5 = MockBuilder('Bad Chroot',
  ...                        WaitingSlave('BuildStatus.CHROOTFAIL'))

  >>> builder6 = MockBuilder('I am out of order',
  ...                        WaitingSlave('BuildStatus.BUILDERFAIL'))

  >>> builder7 = MockBuilder('I am busy', BuildingSlave())

  >>> builder8 = MockBuilder('I was aborted', AbortedSlave())

  >>> builder9 = MockBuilder('I am trying to terminate the child process',
  ...                        AbortingSlave())

  >>> builder10 = MockBuilder('Package Successfully Built',
  ...                         WaitingSlave('BuildStatus.OK'))

  >>> builder11 = MockBuilder('I am giving this job back',
  ...		               WaitingSlave('BuildStatus.GIVENBACK'))


  >>> buildergroup.builders = [builder1, builder2, builder3, builder4,
  ...                          builder5, builder6, builder7, builder8,
  ...                          builder9, builder10, builder11]

  >>> buildergroup.firstAvailable() is builder2
  True

  Stub classes to emulate Build and BuildQueue

  >>> from canonical.launchpad.interfaces import IBuildSet, IBuilderSet

The slavescanner system also perform build-notification for the
following states: FAILEDTOBUILD and CHROOTWAIT

  >>> class MockBuild:
  ...     def __init__(self, id):
  ...         self.id = id
  ...         self.buildstate = None
  ...         self.builder = None
  ...         self.datebuilt = None
  ...         self.buildduration = None
  ...         self.buildlog = None
  ...         self.dependencies = None
  ...         tmp_build = getUtility(IBuildSet).getByBuildID(7)
  ...         self.archive = tmp_build.archive
  ...         self.distroarchrelease = tmp_build.distroarchrelease
  ...         self.sourcepackagerelease = tmp_build.sourcepackagerelease
  ...         self.pocket = tmp_build.pocket
  ...         self.title = 'Mock Build'
  ...         self.notification_sent = False
  ...         self.is_trusted = tmp_build.is_trusted
  ...         self.binarypackages = ['one', 'two', 'three']
  ...     @property
  ...     def distrorelease(self):
  ...         return self.distroarchrelease.distrorelease
  ...     @property
  ...     def distribution(self):
  ...         return self.distroarchrelease.distrorelease.distribution
  ...     def notify(self, extra_info=None):
  ...         self.notification_sent = True

  >>> import datetime, pytz
  >>> UTC = pytz.timezone('UTC')

  >>> class MockBuildQueue:
  ...     def __init__(self, id, builder, build):
  ...         self.id = id
  ...         self.builder = builder
  ...         self.build = build
  ...         self.buildstart = datetime.datetime(2005, 1, 1, 8, 0, 0,
  ...                                             tzinfo=UTC)
  ...         self.name = "unimportant-name"
  ...         self.files = []
  ...         self.component_name = "main"
  ...         self.archhintlist = ""
  ...         self.is_trusted = build.is_trusted
  ...         self.archrelease = build.distroarchrelease
  ...         self.version = build.sourcepackagerelease.version
  ...     def destroySelf(self):
  ...         pass


Setup also a Librarian client to check indenpendent updateBuild() mechanism:

  >>> from canonical.librarian.interfaces import ILibrarianClient
  >>> librarian = getUtility(ILibrarianClient)

Remove any previous buildmaster ROOT directory, to avoid any garbage
lock conflict (it would be recreated automatically if necessary)

  >>> from canonical.config import config
  >>> import shutil
  >>> import os
  >>> if os.access(config.builddmaster.root, os.F_OK):
  ...     shutil.rmtree(config.builddmaster.root)

Let's check the procedures to verify/collect running build process:

  WAITING - PACKAGEFAIL -> Package has failed to build, notice from
  builder is stored, but Build.buildstate is mark as 'Failed to Build':

  >>> bqItem3 = MockBuildQueue(1, builder3, MockBuild(1))
  >>> buildergroup.updateBuild(bqItem3, librarian)
  >>> bqItem3.build.builder is not None
  True
  >>> bqItem3.build.datebuilt is not None
  True
  >>> bqItem3.build.buildduration is not None
  True
  >>> bqItem3.build.buildlog is not None
  True
  >>> bqItem3.build.notification_sent
  True
  >>> bqItem3.build.buildstate.title
  'Failed to build'

  WAITING - DEPWAIT -> a required dependency is missing, again notice
  from builder, but Build.buildstate has the right state:

  >>> bqItem4 = MockBuildQueue(2, builder4, MockBuild(2))
  >>> buildergroup.updateBuild(bqItem4, librarian)
  CRITICAL:root:***** Missing Dependency build is MANUALDEPWAIT *****
  >>> bqItem4.build.builder is not None
  True
  >>> bqItem4.build.datebuilt is not None
  True
  >>> bqItem4.build.buildduration is not None
  True
  >>> bqItem4.build.buildlog is not None
  True
  >>> bqItem4.build.notification_sent
  False
  >>> bqItem4.build.dependencies
  'baz (>= 1.0.1)'
  >>> bqItem4.build.buildstate.title
  'Dependency wait'

  WAITING - CHROOTFAIL -> the Chroot for this distrorelease is damage, nor
  builder, but right state stored in Build entry:

  >>> bqItem5 = MockBuildQueue(3, builder5, MockBuild(3))
  >>> buildergroup.updateBuild(bqItem5, librarian)
  CRITICAL:root:***** Bad Chroot is CHROOTWAIT *****
  >>> bqItem5.build.builder is not None
  True
  >>> bqItem5.build.datebuilt is not None
  True
  >>> bqItem5.build.buildduration is not None
  True
  >>> bqItem5.build.buildlog is not None
  True
  >>> bqItem5.build.notification_sent
  True
  >>> bqItem5.build.buildstate.title
  'Chroot problem'

  WAITING - BUILDERFAIL -> builder has failed by internal error, job is
  available for next build round:

  >>> bqItem6 = MockBuildQueue(4, builder6, MockBuild(4))
  >>> buildergroup.updateBuild(bqItem6, librarian)
  WARNING:root:***** I am out of order has failed *****
  >>> builder6.failnotes
  'Builder returned BUILDERFAIL when asked for its status'

  >>> bqItem6.builder is None
  True
  >>> bqItem6.build.notification_sent
  False
  >>> bqItem6.build.buildstate.title
  'Needs building'

  BUILDING -> builder still processing the job, simply collect the logtail:

  >>> bqItem7 = MockBuildQueue(5, builder7, MockBuild(5))
  >>> buildergroup.updateBuild(bqItem7, librarian)
  >>> bqItem7.build.notification_sent
  False
  >>> bqItem7.builder.name
  'I am busy'
  >>> bqItem7.logtail
  u'This is a build log'

  ABORTED -> builder was aborted, release builder and reset job for
  the next build round:

  >>> bqItem8 = MockBuildQueue(6, builder8, MockBuild(6))
  >>> bqItem8.builder.name
  'I was aborted'
  >>> buildergroup.updateBuild(bqItem8, librarian)
  >>> bqItem8.builder is None
  True

  ABORTING -> builder is trying to terminate its children process, the
  only action master can perform is polling the slave status until it gets
  ABORTED

  >>> bqItem9 = MockBuildQueue(7, builder9, MockBuild(7))
  >>> bqItem9.builder.name
  'I am trying to terminate the child process'
  >>> buildergroup.updateBuild(bqItem9, librarian)
  >>> bqItem9.build.notification_sent
  False
  >>> bqItem9.logtail
  'Waiting for slave process to be terminated'


== Builder WAITING in OK state ==

This situation happens when the builder has finished the job and is
waiting for the master to collect its results.

The build record in question can end up in the following states:

 * FULLYBUILT: when binaries were collected and uploaded correctly;
 * FAILEDTOUPLOAD: binaries were collected but the upload was rejected/failed.


=== Failed to Upload (FAILEDTOUPLOAD) ===


We need to pick a correspondent 'real' build record to satisfy the
internal lookup in 'updateBuild'. For this we choose a BUILDING build
record:

  >>> from canonical.launchpad.interfaces import IBuildSet
  >>> real_build = getUtility(IBuildSet).getByBuildID(8)
  >>> real_build.buildstate.name
  'BUILDING'

  >>> mock_build = MockBuild(8)
  >>> mock_build.buildstate = real_build.buildstate

Build a mock BuildQueueItem using the 'real' Build ID and the
mock_builder and mock_build as information containers:

  >>> bqItem10 = MockBuildQueue(8, builder10, mock_build)

If the build record wasn't updated before/during the updateBuild
(precisely on binary upload time), the build will be considered
FAILEDTOUPLOAD:

  >>> buildergroup.updateBuild(bqItem10, librarian)
  >>> bqItem10.build.builder is not None
  True
  >>> bqItem10.build.datebuilt is not None
  True
  >>> bqItem10.build.buildduration is not None
  True
  >>> bqItem10.build.buildlog is not None
  True
  >>> bqItem10.build.notification_sent
  True
  >>> bqItem10.build.buildstate.title
  'Failed to upload'


=== Successfully collected and uploaded  (FULLYBUILT) ===

Similar to what we have done in FAILEDTOUPLOAD we will map this
procedure to same 'real' build record ID in FULLYBUILT state:

  >>> mock_build = MockBuild(2)
  >>> bqItem10 = MockBuildQueue(2, builder10, mock_build)

Now in order to emulate a successfully binary upload we will update
the mock build record to FULLYBUILT, as the process-upload would do:

  >>> from canonical.lp.dbschema import BuildStatus
  >>> mock_build.buildstate = BuildStatus.FULLYBUILT

Now the updateBuild should recognise this build record as a
Successfully built and uploaded procedure, not sending any
notification and updating the build information:

  >>> buildergroup.updateBuild(bqItem10, librarian)
  >>> bqItem10.build.builder is not None
  True
  >>> bqItem10.build.datebuilt is not None
  True
  >>> bqItem10.build.buildduration is not None
  True
  >>> bqItem10.build.buildlog is not None
  True
  >>> bqItem10.build.notification_sent
  False
  >>> bqItem10.build.buildstate.title
  'Successfully built'


  WAITING -> GIVENBACK - slave requested build record to be
  reschedulled.

  >>> bqItem11 = MockBuildQueue(9, builder11, MockBuild(9))
  >>> buildergroup.updateBuild(bqItem11, librarian)
  WARNING:root:***** 1-1 is GIVENBACK by I am giving this job back *****

Ensure GIVENBACK build preserves the history for future use. (we
can't be sure if logtail will contain any information, because it
depends on how long the build took to be processed and how often we
scanned it)

  >>> bqItem11.builder is None
  True
  >>> bqItem11.buildstart is None
  True
  >>> bqItem11.lastscore
  0
  >>> bqItem11.build.notification_sent
  False
  >>> bqItem11.build.buildstate.title
  'Needs building'


The Builddmaster should crash when collecting builds which are denied in
the given distrorelease/pocket. Anytime it happens we need to manually
investigate why this build end up built. (should never happen in real
cases, and even so should be refused when we try to upload it.)

  >>> from canonical.launchpad.interfaces import IDistributionSet
  >>> bqItem12 = MockBuildQueue(10, builder10, MockBuild(10))
  >>> warty = getUtility(IDistributionSet)['ubuntu']['warty']
  >>> bqItem12.build.distroarchrelease = warty['i386']
  >>> buildergroup.updateBuild(bqItem12, librarian)
  Traceback (most recent call last):
  ...
  AssertionError: Mock Build (10) can not be built for pocket RELEASE: illegal status


The buildlog is collected and compressed locally using gzip algorithm,
let's see how this method works:

  >>> logfile_alias = buildergroup.getLogFromSlave(builder10.slave,
  ...                                              bqItem10, librarian)

  >>> from canonical.launchpad.interfaces import ILibraryFileAliasSet

  >>> logfile = getUtility(ILibraryFileAliasSet)[logfile_alias]

  >>> logfile.filename, logfile.mimetype
  (u'buildlog_ubuntu-hoary-i386.pmount_0.1-1_FULLYBUILT.txt.gz', u'text/plain')


Needed so that the Librarian can serve the new file.

  >>> local_transaction.commit()

Since LibrarianFileAlias does not implement required attributes for
gzip.open() (like tell() or seek()) we are obligated to read it again
in our filesystem.

  >>> import gzip, tempfile, os
  >>> fd, fname = tempfile.mkstemp()
  >>> tmp = open(fname, 'wb')
  >>> tmp.write(logfile.read())
  >>> tmp.close()
  >>> gzip.open(fname).read() == builder10.slave.getFile('buildlog').read()
  True

The happens with urllib instance, we need to download it to the
filesystem before uncompress.

  >>> import urllib
  >>> from_web = urllib.urlopen(logfile.http_url)
  >>> tmp = open(fname, 'wb')
  >>> tmp.write(from_web.read())
  >>> tmp.close()
  >>> gzip.open(fname).read() == builder10.slave.getFile('buildlog').read()
  True

Both access methods work as expected, remove the temporary file used here.

  >>> os.remove(fname)

Check the log from the uploader run has made it into the upload directory:

  >>> failed_dir = os.path.join(config.builddmaster.root, 'failed')
  >>> failed_uploads = os.listdir(failed_dir)
  >>> len(failed_uploads)
  2

  >>> failed_upload = failed_uploads[0]
  >>> uploader_log = open(os.path.join(failed_dir, failed_upload,
  ...                                  'uploader.log'))

  >>> print uploader_log.read()
  INFO    creating lockfile
  DEBUG   Initialising connection.
  DEBUG   Beginning processing
  DEBUG   Creating directory /var/tmp/builddmaster/accepted
  DEBUG   Creating directory /var/tmp/builddmaster/rejected
  DEBUG   Creating directory /var/tmp/builddmaster/failed
  ...
  DEBUG   Rolling back any remaining transactions.
  DEBUG   Removing lock file: /var/lock/process-upload-buildd.lock
  <BLANKLINE>

Remove build upload results root

  >>> shutil.rmtree(config.builddmaster.root)


    BuilddMaster class
    ===================

  >>> bm = BuilddMaster(logging.getLogger(), local_transaction)

Retrive a known DistroArchrelease

  >>> from canonical.launchpad.interfaces import IDistributionSet
  >>> hoary_i386 = getUtility(IDistributionSet)['ubuntu']['hoary']['i386']

Create a totally bogus CHROOT

  >>> from canonical.lp import dbschema
  >>> from canonical.launchpad.database import LibraryFileAlias
  >>> from canonical.launchpad.database import PocketChroot
  >>> pocket = dbschema.PackagePublishingPocket.RELEASE
  >>> chroot = LibraryFileAlias.get(1)
  >>> p = PocketChroot(distroarchreleaseID=hoary_i386.id,
  ...                  pocket=pocket, chroot=chroot)


As we do when building the BuildQueue entries we need to recognise
all available distroarchreleases and figure out which slave builder
is able to build stuff properly for that one.


Initialiase the BuildMaster with all available distroarchreleases.
Because the sampledata builders are busy we issue and warning stating that.

  >>> from canonical.launchpad.interfaces import IDistroArchReleaseSet
  >>> for dar in sorted(getUtility(IDistroArchReleaseSet),
  ...                   key=lambda dar: (dar.distrorelease.distribution.name,
  ...                                    dar.distrorelease.name,
  ...                                    dar.architecturetag)):
  ...     bm.addDistroArchRelease(dar)
  ...     bm.setupBuilders(dar)
  WARNING:root.builders.x86:No builders are available

Inspect private attribute _archrelease contents. Remember
archrelease was fetched in the beginning of the test.

  >>> len(bm._archreleases)
  1

It should be hoary/x86:

  >>> bm._archreleases.keys()[0].title
  u'The Hoary Hedgehog Release for i386 (x86)'

  >>> real_buildergroup = bm._archreleases[hoary_i386]['builders']

  >>> real_buildergroup.firstAvailable() is None
  True

Scan active builders looking for information about current jobs,
collect result of finished jobs, everything is stored directly in
the Launchpad DB. (simply check if it doesn't explode)

  >>> bm.scanActiveBuilders()

Create a list of jobs separated by processor to turn the dispatch
process easier, then try to dispatch them according his processor and
the available builder slaves at moment.

  >>> byproc = bm.sortAndSplitByProcessor()
  >>> len(byproc)
  1

Inspect the organized list content:

  >>> for proc, queueItems in byproc.iteritems():
  ...     for item in queueItems:
  ...         proc.name, item.id, item.build.buildstate.name
  (u'x86', 2, 'NEEDSBUILD')

Invoke dispacher on the available list: (no builder available atm)

  >>> for proc, queueItems in byproc.iteritems():
  ...     bm.dispatchByProcessor(proc, queueItems)

We wish now to check what happens if we dispatchByProcessor and there
are builds for now superseded source package releases in the queue.

This involves subbing in a scarily large amount of crud, so here
goes nothing.

  >>> from canonical.lp.dbschema import PackagePublishingStatus

  >>> class MockBG:
  ...     def firstAvailable(self, is_trusted=False):
  ...         return "Something which is not None"

  >>> class MockProcessor:
  ...     id = "fakeprocessor"
  ...     name = "fakeprocessor"

  >>> class MockPubRecord:
  ...     def __init__(self):
  ...         self.status = PackagePublishingStatus.SUPERSEDED

  >>> class MockSPR:
  ...     publishings = [MockPubRecord()]

  >>> from canonical.buildd.utils import notes
  >>> notes[MockProcessor()]["builders"] = MockBG()
  >>> qitem = MockBuildQueue(1000, None, MockBuild(1001))
  >>> qbuild = qitem.build
  >>> queue = [qitem]
  >>> qitem.build.sourcepackagerelease = MockSPR()
  >>> bm.dispatchByProcessor(MockProcessor(), queue)

  >>> qbuild.buildstate
  <Item SUPERSEDED (5) ...>


Initialize BuildQueue missing attributes for building:

  >>> bqItem3.version = 'Demo'
  >>> bqItem3.archrelease = hoary_i386
  >>> bqItem3.build.archive = bqItem3.build.distroarchrelease.main_archive


Request a Mock slave build process, see OkSlave() class implementation
for further details:

Get a builder from the sample data:

  >>> a_builder = getUtility(IBuilderSet).get(1)

Force the builder to be 'ok' as the code required to do this automatically is
not yet factored into the content class.

  >>> a_builder.builderok = True

Override the slave with one that will claim to be 'OK'

  >>> a_builder.setSlaveForTesting(OkSlave())

  >>> bm.startBuild(real_buildergroup, a_builder, bqItem3)
  ensurepresent called
  OkSlave BUILDING

When there is no chroot it should not alter the buildstate:

  >>> from canonical.lp.dbschema import PackagePublishingPocket
  >>> PocketChroot.selectBy(
  ...     distroarchrelease=bqItem3.archrelease,
  ...     pocket=PackagePublishingPocket.SECURITY).count()
  0

  >>> bqItem3.build.pocket = PackagePublishingPocket.SECURITY
  >>> bqItem3.build.buildstate = BuildStatus.NEEDSBUILD

Also reset the builder to be 'ready to build' by replacing the slave (where the
actual state for building or not is stored).

  >>> a_builder.setSlaveForTesting(OkSlave())

  >>> bm.startBuild(real_buildergroup, a_builder, bqItem3)

  >>> bqItem3.build.buildstate.name
  'NEEDSBUILD'


Check if builddmaster stops before starting building a denied build, for
this we will create the previous missing CHROOT for
ubuntu/hoary/i386/SECURITY

  >>> p = PocketChroot(distroarchreleaseID=hoary_i386.id,
  ...                  pocket=PackagePublishingPocket.SECURITY,
  ...                  chroot=LibraryFileAlias.get(2))

  >>> hoary_i386.distrorelease.releasestatus.name
  'DEVELOPMENT'

Since hoary is in development, we should not be able to dispatch
builds for post-release pockets:

  >>> bm.startBuild(real_buildergroup, a_builder, bqItem3)
  Traceback (most recent call last):
  ...
  AssertionError: Mock Build (1) can not be built for pocket SECURITY: invalid pocket due to the release status of hoary.


