Soyuz Upload Test
-----------------

This test will:

  * Turn the poppy FTP server on
  * Upload packages
  * Check result
  * Kill the FTP server
  * Import gpg key for katie
  * Register gpg key for katie
  * Register the katie user in the right team
  * Turn on the zeca keyserver
  * Include the non_free component in the database
  * Run process-upload.py
  * Check result
  * Mark packages as ACCEPTED
  * Runs process-accepted.py
  * Check results
  * Cleanup


Uploading Packages
------------------


We need the librarian for this test.

  >>> from canonical.librarian.ftests.harness import LibrarianTestSetup
  >>> LibrarianTestSetup().setUp()


First, let's create a temporary directory where we'll put
uploaded files in.

  >>> import os
  >>> import tempfile
  >>> temp_dir = tempfile.mkdtemp()
  >>> incoming_dir = os.path.join(temp_dir, "incoming")
  >>> accepted_dir = os.path.join(temp_dir, "accepted")
  >>> os.mkdir(incoming_dir)


Now, let's create a subprocess running the poppy FTP server. It won't
call the upload processing tool. We'll do that ourselves in our test,
so that we can control what's going on.

  >>> from canonical.archivepublisher.ftests import (
  ...     PoppyTestSetup, SoyuzUploadError)
  >>> poppy = PoppyTestSetup(incoming_dir)
  >>> poppy.startPoppy()

Connect to the server and login. We'll keep trying to connect until
the server dies or the connection succeeds.

  >>> import ftplib, socket
  >>> ftp = ftplib.FTP()
  >>> while True:
  ...    try:
  ...        reply = ftp.connect("localhost", 3421)
  ...    except socket.error:
  ...        if not poppy.alive:
  ...            raise SoyuzUploadError('Server can not start.')
  ...    else:
  ...        break
  >>> ftp.login("ubuntutest", "")
  '230 Login Successful.'
  >>> ftp.cwd("/")
  '250 CWD command successful.'


Good.. let's send all packages we have in the test directory to
the poppy server. We send each package set on a different ftp
session.

  >>> from canonical.archivepublisher.tagfiles import parse_tagfile
  >>> from canonical.config import config
  >>> from cStringIO import StringIO
  >>> import glob
  >>> import time
  >>>
  >>> test_files_dir = os.path.join(config.root,
  ...                               "lib/canonical/launchpad/scripts/"
  ...                               "ftests/upload_test_files/")
  ...
  >>> changes = glob.glob(test_files_dir + "*.changes")
  >>> sent_filenames = []
  >>> uploads = []
  >>> package_names = []
  >>>

  XXX cprov 20060125: poppy still having a weird behaviour during the
  file transfer, it suddenly closes the connection due inactivity.
  That's why we keep polling the 'ftp.sock' attribute and reconnect if
  it is gone. Bug # 29645

  >>> for changes_filepath in changes:
  ...
  ...     if not ftp.sock:
  ...         assert ftp.connect("localhost", 3421).startswith("220 ")
  ...         assert ftp.login("ubuntutest", "") == '230 Login Successful.'
  ...
  ...     tf = parse_tagfile(changes_filepath)
  ...
  ...     package_names.append(tf["source"])
  ...
  ...     send_filepaths = [changes_filepath]
  ...     send_filepaths.extend([os.path.join(test_files_dir, line.split()[-1])
  ...                            for line in tf["files"].splitlines() if line])
  ...
  ...     sent_filenames.extend(os.path.basename(filepath)
  ...                           for filepath in send_filepaths)
  ...
  ...     for filepath in send_filepaths:
  ...         reply = ftp.storbinary("STOR "+os.path.basename(filepath),
  ...                                open(filepath))
  ...         assert reply == '226 Transfer successful.'
  ...
  ...     uploads.append(send_filepaths)
  ...
  ...     assert ftp.quit() == '221 Goodbye.'


We don't want to block forever reading data from the process, since
it's a daemon and should not die until we ask it to. So, we first
set the stdout to non-blocking...

  >>> poppy.setNonBlocking()

Then, we create a set of the filenames we expect to see in the
FTP server process output, and wait until all of them have been
shown.

This is a little bit tricky because we won't simply try to read
the process output in a blocking way, since any failure in the
FTP process would block automated tests. Instead, we define a
timeout between output data. If the process doesn't provide new
data in the given number seconds, we report a failure.

  >>> poppy.verify_output(list(sent_filenames))

At that point we must have a bunch of directories in the upload
base directory named <TIMESTAMP>-XXXXXX, each one as a result of
each FTP session. Below we ensure that, and also that the content
of these files match the uploaded ones.

  >>> import md5
  >>> def get_md5(filename):
  ...     return md5.new(open(filename).read()).digest()

  >>> def get_upload_dir(num):
  ...     for upload_dir in os.listdir(incoming_dir):
  ...         if upload_dir.endswith("%06d" % num):
  ...             return os.path.join(incoming_dir, upload_dir)

  >>> for i, sent_filenames in enumerate(uploads):
  ...     upload_dir = get_upload_dir(i+1)
  ...     assert len(os.listdir(upload_dir)) == len(sent_filenames)
  ...     for filename in sent_filenames:
  ...         upload_filename = os.path.join(upload_dir,
  ...                                        os.path.basename(filename))
  ...         assert os.path.isfile(upload_filename)
  ...         assert get_md5(filename) == get_md5(upload_filename)


Right, that's all we need from the FTP server. We don't need it anymore,
so we'll just kill the process.

  >>> status = poppy.killPoppy()


Processing Uploads
------------------

Before asking the system to process the upload, we must prepare the
database to receive it. This consists mainly of adding the katie
user, since that's the email used in the Changed-By field for the
.changes files we are going to process, and the ftpmaster@canonical.com
GPG key, since that's the one used to sign the .changes file.

We don't have to check the .dsc file, since we're using the 'sync'
policy in process-upload.py.

XXX: gustavo 20051210
     It might be interesting to move these entries into the sample data
     rather than leaving it here. On the other hand, it's nice to have
     it here as we have a good reference of what the uploading
     procedure depends upon.

So, load the GPG key:

  >>> from canonical.launchpad.ftests.keys_for_tests import gpgkeysdir
  >>> from canonical.launchpad.interfaces import IGPGHandler
  >>> from zope.component import getUtility
  >>> gpg_handler = getUtility(IGPGHandler)
  >>> key_path = os.path.join(gpgkeysdir, 'ftpmaster@canonical.com.pub')
  >>> key_data = open(key_path).read()
  >>> key = gpg_handler.importKey(key_data)
  >>> assert key is not None
  >>> key.fingerprint
  '33C0A61893A5DC5EB325B29E415A12CAC2F30234'


Create the katie user and register it in a team that is allowed to
do uploads:

  >>> from canonical.launchpad.interfaces import IPersonSet, IEmailAddressSet
  >>> name, address = "Katie", "katie@rockhopper.ubuntu.com"
  >>> user = getUtility(IPersonSet).ensurePerson(address, name)
  >>> assert user is not None
  >>> email = getUtility(IEmailAddressSet).getByEmail(address)
  >>> user.validateAndEnsurePreferredEmail(email)

  >>> uploader_team = getUtility(IPersonSet).getByName("ubuntu-team")
  >>> assert uploader_team is not None

  >>> uploader_team.addMember(user)


Assign the loaded GPG key to the katie user.

  >>> from canonical.launchpad.interfaces import IGPGKeySet
  >>> from canonical.lp.dbschema import GPGKeyAlgorithm
  >>> key_set = getUtility(IGPGKeySet)
  >>> user_key = key_set.new(ownerID=user.id, keyid=key.keyid,
  ...                        fingerprint=key.fingerprint,
  ...                        algorithm=GPGKeyAlgorithm.items[key.algorithm],
  ...                        keysize=key.keysize, can_encrypt=key.can_encrypt,
  ...                        active=True)


Now we want to turn on the zeca key server to provide the key we
just imported. Remember that process-upload.py is running as
a different process.

  >>> from canonical.zeca.ftests.harness import ZecaTestSetup
  >>> ZecaTestSetup().setUp()


Include non-free in the database. This will be done by the
NascentUpload in the 'sync' policy in the future.

  >>> from canonical.launchpad.interfaces import IComponentSet
  >>> component_set = getUtility(IComponentSet)
  >>> non_free = component_set.new("non-free")
  >>> contrib = component_set.new("contrib")
  >>> import transaction
  >>> transaction.commit()

That's all for the FTP server. Now we must process the uploaded packages.
This is done by running process-upload.py on each upload directory.

  >>> import subprocess, sys
  >>> script = os.path.join(config.root, "scripts/process-upload.py")
  >>> process = subprocess.Popen([sys.executable, script, "--no-mails", "-q",
  ...                             "-C", "sync", temp_dir])

  >>> process.wait()
  0

Let's check if packages were uploaded correctly.

  >>> from canonical.launchpad.database import (
  ...     SourcePackageRelease, SourcePackageName)
  >>> from pprint import pprint

  >>> spn = SourcePackageName.selectOneBy(name="drdsl")
  >>> spn.name
  u'drdsl'
  >>> spr = SourcePackageRelease.selectOneBy(sourcepackagenameID=spn.id)
  >>> spr.title
  u'drdsl - 1.2.0-0ubuntu1'
  >>> spr.name
  u'drdsl'
  >>> spr.version
  u'1.2.0-0ubuntu1'
  >>> spr.component.name
  u'non-free'
  >>> spr.section.name
  u'comm'
  >>> spr.maintainer.displayname
  u'Matthias Klose'
  >>> pprint(sorted([sprf.libraryfile.filename for sprf in spr.files]))
  [u'drdsl_1.2.0-0ubuntu1.diff.gz',
   u'drdsl_1.2.0-0ubuntu1.dsc',
   u'drdsl_1.2.0.orig.tar.gz']
  >>> spr.format.name
  'DPKG'
  >>> spr.urgency.name
  'LOW'
  >>> spr.uploaddistrorelease.name
  u'breezy-autotest'


Same thing for etherwake:

  >>> spn = SourcePackageName.selectOneBy(name="etherwake")
  >>> spn.name
  u'etherwake'
  >>> spr = SourcePackageRelease.selectOneBy(sourcepackagenameID=spn.id)
  >>> spr.title
  u'etherwake - 1.08-1'
  >>> spr.name
  u'etherwake'
  >>> spr.version
  u'1.08-1'
  >>> spr.component.name
  u'main'
  >>> spr.section.name
  u'net'
  >>> spr.maintainer.displayname
  u'Alain Schroeder'
  >>> pprint(sorted([sprf.libraryfile.filename for sprf in spr.files]))
  [u'etherwake_1.08-1.diff.gz',
   u'etherwake_1.08-1.dsc',
   u'etherwake_1.08.orig.tar.gz']
  >>> spr.format.name
  'DPKG'
  >>> spr.urgency.name
  'LOW'
  >>> spr.uploaddistrorelease.name
  u'breezy-autotest'


  >>> def get_accepted_dir(num):
  ...     for upload_dir in os.listdir(accepted_dir):
  ...         if upload_dir.endswith("%06d" % num):
  ...             return os.path.join(accepted_dir, upload_dir)

  >>> for i, sent_filenames in enumerate(uploads):
  ...     upload_dir = get_accepted_dir(i+1)
  ...     assert len(os.listdir(upload_dir)) == len(sent_filenames)
  ...     for filename in sent_filenames:
  ...         upload_filename = os.path.join(upload_dir,
  ...                                        os.path.basename(filename))
  ...         assert os.path.isfile(upload_filename)
  ...         assert get_md5(filename) == get_md5(upload_filename)


Now let's see if all of them are in the DistroReleaseQueue marked
as NEW and RELEASE.

  >>> from canonical.launchpad.database import DistroReleaseQueueSource
  >>> for name in package_names:
  ...     spn = SourcePackageName.selectOneBy(name=name)
  ...     spr = SourcePackageRelease.selectOneBy(sourcepackagenameID=spn.id)
  ...     drqs = DistroReleaseQueueSource.selectOneBy(sourcepackagereleaseID=spr.id)
  ...     assert drqs.distroreleasequeue.status.name == 'NEW'
  ...     assert drqs.distroreleasequeue.pocket.name == 'RELEASE'


Processing NEW Items
----------------------

The processing of NEW-queue-entries checks the integrity of uploads
candidates and promote them to ACCEPTED, the failures are kept
as NEW

  >>> from canonical.launchpad.interfaces import (
  ...     IDistributionSet, QueueInconsistentStateError)
  >>> from canonical.lp.dbschema import DistroReleaseQueueStatus

Since we landed correct security adapters for DistroReleaseQueue,
we need to perform further actions logged in as an admins, which have
launchpad.Edit on the records:

  >>> from canonical.launchpad.ftests import login
  >>> login("foo.bar@canonical.com")

  >>> distro = getUtility(IDistributionSet).getByName('ubuntutest')
  >>> release = distro['breezy-autotest']

Let's test IHasQueueItems.getQueueItems:

  >>> new_items = release.getQueueItems(DistroReleaseQueueStatus.NEW)
  >>> new_items.count()
  2

Querying by status and a name term:

  >>> items = release.getQueueItems(DistroReleaseQueueStatus.NEW,
  ...                                    name='dr')
  >>> items.count()
  1

  >>> items[0].sources[0].sourcepackagerelease.name
  u'drdsl'
  >>> items[0].sources[0].sourcepackagerelease.version
  u'1.2.0-0ubuntu1'

Querying by status, name and version terms:

  >>> items = release.getQueueItems(DistroReleaseQueueStatus.NEW,
  ...                               name='dr', version='1.2')
  >>> items.count()
  1

  >>> items = release.getQueueItems(DistroReleaseQueueStatus.NEW,
  ...                               name='dr', version='1.5')
  >>> items.count()
  0

Using exact_match argument:

As you can see exact_match arguments affects both, name & version:

XXX cprov 20060125: Andrew suggest we can split the exact_match
attribute in two, as exact_name & exact_version, which might be
a good idea, since it produce a more controllable behaviour.
See bug # 29642

  >>> items = release.getQueueItems(DistroReleaseQueueStatus.NEW,
  ...                      name='dr', version='1.2', exact_match=True)
  >>> items.count()
  0

  >>> items = release.getQueueItems(DistroReleaseQueueStatus.NEW,
  ...          name='drdsl', version='1.2.0-0ubuntu1', exact_match=True)
  >>> items.count()
  1

Using getQueueItem to inspect current NEW queue and accept them.

  >>> queue_items = release.getQueueItems(DistroReleaseQueueStatus.NEW)
  >>> L = []
  >>> for queue_item in queue_items:
  ...      try:
  ...          queue_item.setAccepted()
  ...      except QueueInconsistentStateError, e:
  ...          L.append("%s %s" % (queue_item.sourcepackagename.name, e))
  ...      else:
  ...          L.append("%s %s" % (queue_item.sourcepackagename.name, 'ACCEPTED'))
  >>> L.sort()
  >>> print "\n".join(L)
  drdsl Component "non-free" is not allowed in breezy-autotest
  etherwake ACCEPTED

XXX cprov 20060412: We must flush these changes so that it gets out of
the cache and  into the database. Without this process-accepted.py
wouldn't see the changes. Reported in bug # 3989

  >>> from canonical.database.sqlbase import flush_database_updates
  >>> flush_database_updates()
  >>> transaction.commit()


Now we process the accepted queue items, one more time.

  >>> script = os.path.join(config.root, "scripts", "process-accepted.py")
  >>> process = subprocess.Popen([sys.executable, script, "ubuntutest"])
  >>> process.wait()
  0

These packages must now be in the publishing history. Let's check it.

  >>> from canonical.launchpad.database import (
  ...    SecureSourcePackagePublishingHistory as SSPPH)
  >>> from canonical.lp.dbschema import PackagePublishingStatus
  >>> package_names.sort()
  >>> for name in package_names:
  ...     spn = SourcePackageName.selectOneBy(name=name)
  ...     spr = SourcePackageRelease.selectOneBy(sourcepackagenameID=spn.id)
  ...     sspph = SSPPH.selectOneBy(sourcepackagereleaseID=spr.id)
  ...     if sspph:
  ...         print name, sspph.status.title
  ...     else:
  ...         print name, 'not Published'
  drdsl not Published
  etherwake Pending


Invoke Publisher script against the 'ubuntutest' distribution:

  >>> script = os.path.join(config.root, "scripts", "publish-distro.py")
  >>> process = subprocess.Popen([sys.executable, script, "-Cq",
  ...                             "-d", "ubuntutest"],
  ...                            stdout=subprocess.PIPE,
  ...                            stderr=subprocess.PIPE)
  >>> garbage = process.stderr.read()
  >>> garbage = process.stdout.read()
  >>> process.wait()
  0

XXX cprov 20060412: bug # 3989

  >>> flush_database_updates()
  >>> transaction.commit()
  >>> from canonical.database.sqlbase import _clearCache
  >>> _clearCache()

Check if the 'etherwake' source package was correctly published and is
in the filesystem archive, we are looking for the DSC, the gzipped
original source and the gzipped package diff:

  >>> len(os.listdir("/var/tmp/archive/ubuntutest/pool/main/e/etherwake"))
  3

Check the generation of a correct Sources tag file for the main
component of ubuntutest/breezy-autotest, containing the only the
required entry for 'etherwake':

  >>> print open("/var/tmp/archive/ubuntutest/dists/breezy-autotest"
  ...            "/main/source/Sources").read() + '\nEND'
  Package: etherwake
  Binary: etherwake
  Version: 1.08-1
  Maintainer: Alain Schroeder <alain@debian.org>
  Build-Depends: debhelper (>> 2.0)
  Architecture: any
  Standards-Version: 3.5.10.0
  Format: 1.0
  Directory: pool/main/e/etherwake
  Files:
   f13711c5b8261fbb77b43ae0e8ba9360 566 etherwake_1.08-1.dsc
   c2dc10f98bac012b900fd0b46721fc80 4455 etherwake_1.08.orig.tar.gz
   95c1e89e3ad7bc8740793bdf7aeb7334 4145 etherwake_1.08-1.diff.gz
  <BLANKLINE>
  <BLANKLINE>
  END

Invoke changeOverride on just published etherwake moving it to
component 'universe'.

  >>> ubuntutest = getUtility(IDistributionSet)['ubuntutest']
  >>> breezy_autotest = ubuntutest['breezy-autotest']
  >>> etherwake = breezy_autotest.getSourcePackage('etherwake')
  >>> etherwake_drspr = etherwake.currentrelease
  >>> etherwake_drspr.changeOverride(
  ...     new_component=getUtility(IComponentSet)['universe'])

Check if we have new pending publishing record as expected

  >>> for pub in SSPPH.selectBy(
  ...    sourcepackagereleaseID=etherwake_drspr.sourcepackagerelease.id,
  ...    orderBy=['id']):
  ...    print pub.id, pub.status.name, pub.component.name, pub.pocket.name
  20 PUBLISHED main RELEASE
  21 PENDING universe RELEASE

Force database changes, so they can be used by the external script properly.

XXX cprov 20060412: bug # 3989
  >>> flush_database_updates()
  >>> transaction.commit()

Invoke Publisher script again to land our changes in the archive

  >>> script = os.path.join(config.root, "scripts", "publish-distro.py")
  >>> process = subprocess.Popen([sys.executable, script, "-q",
  ...                             "-d", "ubuntutest"],
  ...                            stdout=subprocess.PIPE,
  ...                            stderr=subprocess.PIPE)
  >>> garbage = process.stderr.read()
  >>> garbage = process.stdout.read()
  >>> process.wait()
  0

Invalidates SQLObject cache to cope with publisher.

  >>> _clearCache()

Check the publishing history again

  >>> for pub in SSPPH.selectBy(
  ...    sourcepackagereleaseID=etherwake_drspr.sourcepackagerelease.id,
  ...    orderBy=['id']):
  ...    print pub.id, pub.status.name, pub.component.name, pub.pocket.name
  20 PENDINGREMOVAL main RELEASE
  21 PUBLISHED universe RELEASE

Check if the package was moved properly to the component 'universe':

  >>> main_sources = open("/var/tmp/archive/ubuntutest/dists/breezy-autotest"
  ...                     "/main/source/Sources").read()
  >>> print main_sources + '\nEND'
  <BLANKLINE>
  END

  >>> universe_sources = open("/var/tmp/archive/ubuntutest/dists/"
  ...                         "breezy-autotest/universe/source/"
  ...                         "Sources").read()
  >>> print universe_sources + '\nEND'
  Package: etherwake
  ...
  END

Nice! That's enough for now.. let's kill the process and clean
everything up.

  >>> import shutil
  >>> shutil.rmtree(temp_dir)

Remove the test archive from filesystem.

  >>> shutil.rmtree("/var/tmp/archive/")
  >>> ZecaTestSetup().tearDown()
  >>> LibrarianTestSetup().tearDown()


Feito! ;-)


vim:ft=doctest:ts=4:sw=4:et

